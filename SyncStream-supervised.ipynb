{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0395958",
   "metadata": {},
   "source": [
    "# Concept Drift Detection With SyncStream\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64c1b91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c27141",
   "metadata": {},
   "source": [
    "### SEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ed77ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    attrib1   attrib2   attrib3      class\n",
      "0  7.308782  4.100808  2.077148  b'groupB'\n",
      "1  5.833539  0.422983  7.616747  b'groupA'\n",
      "2  1.397627  6.949480  8.052278  b'groupB'\n",
      "3  2.750299  0.753878  6.105915  b'groupA'\n",
      "4  2.049135  6.233638  1.847071  b'groupB'\n",
      "(30000, 3)\n",
      "(30000,)\n",
      "(70000, 3)\n",
      "(70000,)\n"
     ]
    }
   ],
   "source": [
    "# data, meta = arff.loadarff(\"synthetic_data/abrupt_drift/sea_1_abrupt_drift_0_noise_balanced.arff\")\n",
    "# data, meta = arff.loadarff(\"synthetic_data/gradual_drift/sea_1_gradual_drift_0_noise_balanced_1.arff\")\n",
    "# data, meta = arff.loadarff(\"synthetic_data/gradual_drift/sea_1_gradual_drift_0_noise_balanced_5.arff\")\n",
    "# data, meta = arff.loadarff(\"synthetic_data/gradual_drift/sea_1_gradual_drift_0_noise_balanced_05.arff\")\n",
    "# data, meta = arff.loadarff(\"synthetic_data/gradual_drift/sea_1_gradual_drift_0_noise_balanced_10.arff\")\n",
    "data, meta = arff.loadarff(\"synthetic_data/gradual_drift/sea_1_gradual_drift_0_noise_balanced_20.arff\")\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "le = LabelEncoder()\n",
    "X = df[[\"attrib1\", \"attrib2\", \"attrib3\"]]\n",
    "y = le.fit_transform(df[\"class\"].str.decode(\"utf-8\"))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.30, shuffle=False)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902b48ac",
   "metadata": {},
   "source": [
    "### AGRAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2576b58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data, meta = arff.loadarff(\"agraw1_1_abrupt_drift_0_noise_balanced.arff\")\n",
    "# # data, meta = arff.loadarff(\"agraw2_1_abrupt_drift_0_noise_balanced.arff\")\n",
    "\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# # print(df.head())\n",
    "\n",
    "# le = LabelEncoder()\n",
    "# te = TargetEncoder(cols=[\"elevel\", \"car\", \"zipcode\"], smoothing=0, return_df=True)\n",
    "\n",
    "# X = df.drop(columns=[\"class\"])\n",
    "# y = le.fit_transform(df[\"class\"].str.decode(\"utf-8\"))\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.30, shuffle=False)\n",
    "\n",
    "# X_train = te.fit_transform(X_train, y_train)\n",
    "# X_test = te.transform(X_test)\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train.shape)\n",
    "# print(X_test.shape)\n",
    "# print(y_test.shape)\n",
    "\n",
    "# X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3503ea7a",
   "metadata": {},
   "source": [
    "### Optimise hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "599688da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k_range = range(7, 21)\n",
    "\n",
    "# k_scores = []\n",
    "\n",
    "# for k in k_range:\n",
    "#     model = KNeighborsClassifier(n_neighbors=k)\n",
    "#     k_scores.append(cross_val_score(model, X_train.values, y_train, cv=10).mean()) \n",
    "\n",
    "# plt.plot(k_range, k_scores)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba87656",
   "metadata": {},
   "source": [
    "### Train a generic model to evaluate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e496a1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = KNeighborsClassifier(n_neighbors=13)\n",
    "# model.fit(X_train.values, y_train)\n",
    "\n",
    "# prediction = model.predict([[7.3, 4.1, 2.1]])\n",
    "# print(le.inverse_transform(prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cadc20f",
   "metadata": {},
   "source": [
    "### Divide the test data into batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5656823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3)\n",
      "(10000, 3)\n"
     ]
    }
   ],
   "source": [
    "X_ref_batch = np.array_split(X_train, 3)[2]\n",
    "y_ref_batch = np.array_split(y_train, 3)[2]\n",
    "\n",
    "X_test_batches = np.array_split(X_test, 7)\n",
    "y_test_batches = np.array_split(y_test, 7)\n",
    "\n",
    "print(X_ref_batch.shape)\n",
    "print(X_test_batches[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdddce1c",
   "metadata": {},
   "source": [
    "### Compute model accuracy on each batch and verify drop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38cda7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accs = [model.score(X_ref_batch.values, y_ref_batch)]\n",
    "\n",
    "# for batch in range(len(X_test_batches)):\n",
    "#     accs.append(model.score(X_test_batches[batch].values, y_test_batches[batch]))\n",
    "    \n",
    "# plt.bar(range(0, len(X_test_batches) + 1), accs)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6cbea1",
   "metadata": {},
   "source": [
    "### Implement label-independent drift detectors:\n",
    "\n",
    "### SyncStream-PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "115752fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=1)\n",
    "\n",
    "def detect_drift_pca(values, previous_eigenvector):\n",
    "    pca.fit(values)\n",
    "    angle = np.degrees(np.arccos(np.dot(pca.components_[0], previous_eigenvector)))\n",
    "    detected = angle > 40\n",
    "    print(pca.components_[0])\n",
    "    print(angle)\n",
    "    return detected, pca.components_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc94f1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "batch: 0\n",
      "label: groupB\n",
      "[ 0.68126352 -0.72847937  0.072096  ]\n",
      "\n",
      "\n",
      "batch: 0\n",
      "label: groupA\n",
      "[ 0.02907893 -0.01180819  0.99950737]\n",
      "\n",
      "\n",
      "batch: 1\n",
      "prelabel: groupB\n",
      "[-0.71822474  0.68035908 -0.14582439]\n",
      "174.52697673663346\n",
      "\n",
      "\n",
      "batch: 1\n",
      "prelabel: groupA\n",
      "[-0.02297597  0.03829784  0.99900219]\n",
      "4.140727245676357\n",
      "\n",
      "\n",
      "batch: 2\n",
      "prelabel: groupB\n",
      "[-0.71676873  0.69508396  0.05568549]\n",
      "11.59653321641807\n",
      "\n",
      "\n",
      "batch: 2\n",
      "prelabel: groupA\n",
      "[-6.52748567e-04 -6.36812421e-03  9.99979510e-01]\n",
      "2.861835945604148\n",
      "\n",
      "\n",
      "batch: 3\n",
      "prelabel: groupA\n",
      "[ 0.02087281 -0.03616385  0.99912787]\n",
      "2.1067498160568645\n",
      "\n",
      "\n",
      "batch: 3\n",
      "prelabel: groupB\n",
      "[-0.71967185  0.69322974 -0.03879382]\n",
      "5.418881989564661\n",
      "\n",
      "\n",
      "batch: 4\n",
      "prelabel: groupA\n",
      "[ 0.01437603 -0.00980519 -0.99984858]\n",
      "176.68025888550739\n",
      "\n",
      "\n",
      "batch: 4\n",
      "prelabel: groupB\n",
      "[-0.72280426  0.68814491 -0.06332921]\n",
      "1.446859333225776\n",
      "\n",
      "\n",
      "batch: 5\n",
      "prelabel: groupA\n",
      "[-0.08039775  0.10958865  0.99072021]\n",
      "173.12062933583465\n",
      "\n",
      "\n",
      "batch: 5\n",
      "prelabel: groupB\n",
      "[ 0.71695401 -0.68949642  0.10281843]\n",
      "177.71127751063824\n",
      "\n",
      "\n",
      "batch: 6\n",
      "prelabel: groupB\n",
      "[ 0.63424159 -0.61229574 -0.47205035]\n",
      "34.06912792403\n",
      "\n",
      "\n",
      "batch: 6\n",
      "prelabel: groupA\n",
      "[-0.06919983  0.01930479  0.99741602]\n",
      "5.228433862468772\n",
      "\n",
      "\n",
      "batch: 7\n",
      "prelabel: groupB\n",
      "[-0.69951489  0.70600454  0.11061872]\n",
      "158.15018795459977\n",
      "\n",
      "\n",
      "batch: 7\n",
      "prelabel: groupA\n",
      "[ 0.11024644 -0.08585442  0.99018925]\n",
      "11.945707149466\n",
      "\n",
      "\n",
      "[1, 4, 5, 5, 7]\n"
     ]
    }
   ],
   "source": [
    "train_collections = {}\n",
    "\n",
    "for i in range(len(y_ref_batch)):\n",
    "    label = le.inverse_transform([y_ref_batch[i]])[0]\n",
    "    if not label in train_collections.keys():\n",
    "        train_collections[label] = []\n",
    "    train_collections[label].append(X_ref_batch.values[i])\n",
    "\n",
    "current_eigenvectors = {}\n",
    "\n",
    "for label in train_collections.keys():\n",
    "    pca.fit(train_collections[label])\n",
    "    current_eigenvectors[label] = pca.components_[0]\n",
    "    print(\"\\n\")\n",
    "    print(\"batch: 0\")\n",
    "    print(\"label:\", label)\n",
    "    print(pca.components_[0])\n",
    "    \n",
    "drifts = []\n",
    "\n",
    "for batch in range(len(X_test_batches)):\n",
    "    predictions = le.inverse_transform(y_test_batches[batch])\n",
    "    collections = {}\n",
    "    for i in range(len(predictions)):\n",
    "        prelabel = predictions[i]\n",
    "        if not prelabel in collections.keys():\n",
    "            collections[prelabel] = []\n",
    "        collections[prelabel].append(X_test_batches[batch].values[i])\n",
    "    \n",
    "    for prelabel in collections.keys():\n",
    "        print(\"\\n\")\n",
    "        print(\"batch:\", batch + 1)\n",
    "        print(\"prelabel:\", prelabel)\n",
    "        detected_pca, new_eigenvector = detect_drift_pca(collections[prelabel], current_eigenvectors[prelabel])\n",
    "        current_eigenvectors[prelabel] = new_eigenvector\n",
    "        if (detected_pca):\n",
    "            drifts.append(batch + 1)\n",
    "            \n",
    "print(\"\\n\")\n",
    "print(drifts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62884dc5",
   "metadata": {},
   "source": [
    "### SyncStream-Stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaf4c06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
