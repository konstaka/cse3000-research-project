{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f135bf2a",
   "metadata": {},
   "source": [
    "# Unsupervised concept drift detectors: SyncStream & SCD\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8743c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.2\n",
      "2.5.1.post0\n",
      "1.9.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, OneHotEncoder, OrdinalEncoder\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import rankdata, norm, gaussian_kde\n",
    "from sklearn.utils import resample\n",
    "from statistics import variance\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import sklearn\n",
    "import category_encoders\n",
    "import scipy\n",
    "\n",
    "print(sklearn.__version__)\n",
    "print(category_encoders.__version__)\n",
    "print(scipy.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788c43ac",
   "metadata": {},
   "source": [
    "### Reading the SEA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c5c3d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sea(filename):\n",
    "    data, meta = arff.loadarff(filename)\n",
    "    df = pd.DataFrame(data)\n",
    "#     df = df.iloc[54450:55450,:] # For testing SCD with miniature scale\n",
    "    \n",
    "    X = df[[\"attrib1\", \"attrib2\", \"attrib3\"]]\n",
    "    \n",
    "    X_train, X_test = train_test_split(X, train_size=0.30, shuffle=False)\n",
    "    \n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb7a524",
   "metadata": {},
   "source": [
    "### Reading the AGRAW dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a75d2d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_agraw(filename):\n",
    "    data, meta = arff.loadarff(filename)\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "#     te = TargetEncoder(cols=[\"elevel\", \"car\", \"zipcode\"], smoothing=0, return_df=False)\n",
    "#     ohe = OneHotEncoder()\n",
    "#     oe = OrdinalEncoder()\n",
    "\n",
    "    X = df.drop(columns=[\"class\"])\n",
    "    y = le.fit_transform(df[\"class\"].str.decode(\"utf-8\"))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.30, shuffle=False)\n",
    "\n",
    "#     encoder = 'target'\n",
    "    \n",
    "#     if encoder == 'onehot':\n",
    "#         # OneHotEncoder\n",
    "#         X_train_num = X_train.drop(columns=[\"elevel\", \"car\", \"zipcode\"])\n",
    "#         X_train_cat = X_train[[\"elevel\", \"car\", \"zipcode\"]]\n",
    "#         X_train_cat = ohe.fit_transform(X_train_cat).toarray()\n",
    "#         X_train = np.concatenate([X_train_num, X_train_cat], axis=1)\n",
    "#         X_test_num = X_test.drop(columns=[\"elevel\", \"car\", \"zipcode\"])\n",
    "#         X_test_cat = X_test[[\"elevel\", \"car\", \"zipcode\"]]\n",
    "#         X_test_cat = ohe.transform(X_test_cat).toarray()\n",
    "#         X_test = np.concatenate([X_test_num, X_test_cat], axis=1)\n",
    "#     elif encoder == 'ordinal':\n",
    "#         # OrdinalEncoder\n",
    "#         X_train_num = X_train.drop(columns=[\"elevel\", \"car\", \"zipcode\"])\n",
    "#         X_train_cat = X_train[[\"elevel\", \"car\", \"zipcode\"]]\n",
    "#         X_train_cat = oe.fit_transform(X_train_cat)\n",
    "#         X_train = np.concatenate([X_train_num, X_train_cat], axis=1)\n",
    "#         X_test_num = X_test.drop(columns=[\"elevel\", \"car\", \"zipcode\"])\n",
    "#         X_test_cat = X_test[[\"elevel\", \"car\", \"zipcode\"]]\n",
    "#         X_test_cat = oe.transform(X_test_cat)\n",
    "#         X_test = np.concatenate([X_test_num, X_test_cat], axis=1)\n",
    "#     elif encoder == 'target':\n",
    "#         # TargetEncoder\n",
    "#         X_train = te.fit_transform(X_train, y_train)\n",
    "#         X_test = te.transform(X_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de620dec",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71dced8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess(X_train, X_test, total_batches):\n",
    "#     scaler = MinMaxScaler()\n",
    "\n",
    "#     X_train = pd.DataFrame(scaler.fit_transform(X_train))\n",
    "#     X_test = pd.DataFrame(scaler.transform(X_test))\n",
    "\n",
    "#     X_test_batches = np.array_split(X_test, total_batches)\n",
    "\n",
    "#     return X_train, X_test_batches\n",
    "\n",
    "def ensure_df(data):\n",
    "    checked_data = data\n",
    "    if not isinstance(data, pd.DataFrame):\n",
    "        checked_data = pd.DataFrame(data)\n",
    "    return checked_data\n",
    "\n",
    "def encode(ref_data, test_batches, ref_labels, encoder=None):\n",
    "    encoded_ref_data = ref_data\n",
    "    encoded_test_batches = test_batches\n",
    "    \n",
    "    if encoder == 'onehot':\n",
    "        # OneHotEncoder\n",
    "        ohe = OneHotEncoder()\n",
    "        ref_data_num = ref_data.select_dtypes(include=[np.number])\n",
    "        ref_data_cat = ref_data.select_dtypes(exclude=[np.number])\n",
    "        encoded_ref_data_cat = ohe.fit_transform(ref_data_cat).toarray()\n",
    "        encoded_ref_data = pd.DataFrame(np.concatenate([ref_data_num, encoded_ref_data_cat], axis=1))\n",
    "        encoded_test_batches = []\n",
    "        for batch in range(len(test_batches)):\n",
    "            test_data_num = test_batches[batch].select_dtypes(include=[np.number])\n",
    "            test_data_cat = test_batches[batch].select_dtypes(exclude=[np.number])\n",
    "            encoded_test_data_cat = ohe.transform(test_data_cat).toarray()\n",
    "            encoded_test_batches.append(pd.DataFrame(np.concatenate([test_data_num, encoded_test_data_cat], axis=1)))\n",
    "    elif encoder == 'ordinal':\n",
    "        # OrdinalEncoder\n",
    "        oe = OrdinalEncoder()\n",
    "        ref_data_num = ref_data.select_dtypes(include=[np.number])\n",
    "        ref_data_cat = ref_data.select_dtypes(exclude=[np.number])\n",
    "        encoded_ref_data_cat = oe.fit_transform(ref_data_cat)\n",
    "        encoded_ref_data = pd.DataFrame(np.concatenate([ref_data_num, encoded_ref_data_cat], axis=1))\n",
    "        encoded_test_batches = []\n",
    "        for batch in range(len(test_batches)):\n",
    "            test_data_num = test_batches[batch].select_dtypes(include=[np.number])\n",
    "            test_data_cat = test_batches[batch].select_dtypes(exclude=[np.number])\n",
    "            encoded_test_data_cat = oe.transform(test_data_cat)\n",
    "            encoded_test_batches.append(pd.DataFrame(np.concatenate([test_data_num, encoded_test_data_cat], axis=1)))\n",
    "    elif encoder == 'target' and ref_labels is not None:\n",
    "        # TargetEncoder\n",
    "        cols = ref_data.select_dtypes(exclude=[np.number]).columns\n",
    "        te = TargetEncoder(cols, smoothing=0, return_df=True)\n",
    "        encoded_ref_data = te.fit_transform(ref_data, ref_labels)\n",
    "        encoded_test_batches = []\n",
    "        for batch in range(len(test_batches)):\n",
    "            encoded_test_batches.append(te.transform(test_batches[batch]))\n",
    "        \n",
    "    return encoded_ref_data, encoded_test_batches\n",
    "    \n",
    "def scale(ref_data, test_batches, scaler=None):\n",
    "    scaled_ref_data = ref_data\n",
    "    scaled_test_batches = test_batches\n",
    "    \n",
    "    if scaler == 'minmax':\n",
    "        mms = MinMaxScaler()\n",
    "        scaled_ref_data = pd.DataFrame(mms.fit_transform(ref_data))\n",
    "        scaled_test_batches = list(map(lambda batch: pd.DataFrame(mms.transform(batch)), test_batches))\n",
    "        \n",
    "    return scaled_ref_data, scaled_test_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0e0c24",
   "metadata": {},
   "source": [
    "### Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26a3c593",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(real_drift, detected_drifts, total_batches):\n",
    "    if len(detected_drifts) <= 0:\n",
    "        return 0.0, 1.0\n",
    "    else:\n",
    "        false_positives = list(filter(lambda flagged_batch: flagged_batch < real_drift, detected_drifts))\n",
    "        false_positive_rate = len(false_positives) / (real_drift - 1)\n",
    "        if false_positive_rate < 0:\n",
    "            false_positive_rate = 0.0\n",
    "            \n",
    "        first_detected_drift = detected_drifts[0]\n",
    "        for i in range(len(detected_drifts)):\n",
    "            if detected_drifts[i] >= real_drift:\n",
    "                first_detected_drift = detected_drifts[i]\n",
    "                break\n",
    "        latency = (first_detected_drift - real_drift) / (total_batches - real_drift)\n",
    "        if latency < 0:\n",
    "            latency = 1.0\n",
    "            \n",
    "        return false_positive_rate, latency\n",
    "    \n",
    "def postprocess_rw(real_drifts, detected_drifts, n_batches):\n",
    "    if len(detected_drifts) <= 0:\n",
    "        return 0.0, 0.0\n",
    "    else:\n",
    "        false_positives = list(filter(lambda detected_drift: detected_drift not in real_drifts, detected_drifts))\n",
    "        correct_positives = list(filter(lambda real_drift: real_drift in detected_drifts, real_drifts))\n",
    "\n",
    "        false_positive_rate = len(false_positives) / (n_batches - len(real_drifts))\n",
    "        accuracy = len(correct_positives) / len(real_drifts)\n",
    "        \n",
    "        return false_positive_rate, accuracy\n",
    "    \n",
    "    \n",
    "def graph(deltas, crits, y_label, deltas_reverse=None, crits_reverse=None):\n",
    "#     print(deltas)\n",
    "#     print(crits)\n",
    "#     print(y_label)\n",
    "#     print(deltas_reverse)\n",
    "#     print(crits_reverse)\n",
    "    \n",
    "    plt.ylabel(y_label)\n",
    "    plt.xlabel(\"Test batch\")\n",
    "    x_range = np.arange(1, len(deltas) + 1)\n",
    "    \n",
    "    bar_width = 0.5\n",
    "    offset = 0\n",
    "    if deltas_reverse:\n",
    "        bar_width = 0.25\n",
    "        offset = 0.125\n",
    "    \n",
    "    plt.bar(x_range - offset, deltas, width=bar_width, color=\"b\")\n",
    "    plt.plot(x_range - offset, crits, \"r-\")\n",
    "    if deltas_reverse:\n",
    "        plt.bar(x_range + offset, deltas_reverse, width=bar_width, color=\"c\")\n",
    "        plt.plot(x_range + offset, crits_reverse, \"m-\")\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce52932",
   "metadata": {},
   "source": [
    "### SyncStream-PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b9d981a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def syncstream_pca_all(raw_ref_data, raw_test_batches, ref_labels=None, encoder=None, scaler=None, consecutive=False):\n",
    "    \n",
    "    # Make sure data is in DataFrames\n",
    "    ref_data = ensure_df(raw_ref_data)\n",
    "    test_batches = []\n",
    "    for batch in range(len(raw_test_batches)):\n",
    "        test_batches.append(ensure_df(raw_test_batches[batch]))\n",
    "    \n",
    "    # Encode and scale the data\n",
    "    if encoder:\n",
    "        ref_data, test_batches = encode(ref_data, test_batches, ref_labels, encoder)\n",
    "    if scaler:\n",
    "        ref_data, test_batches = scale(ref_data, test_batches, scaler)\n",
    "        \n",
    "    print(test_batches[0].head())\n",
    "\n",
    "    deltas = []\n",
    "    crits = []\n",
    "    drifts = []\n",
    "\n",
    "    pca = PCA(n_components=1)\n",
    "\n",
    "    pca.fit(ref_data.values)\n",
    "    ref_eigenvector = pca.components_[0]\n",
    "\n",
    "    for batch in range(len(test_batches)):\n",
    "        pca.fit(test_batches[batch].values)\n",
    "        batch_eigenvector = pca.components_[0]\n",
    "        measured_angle = np.degrees(np.arccos(np.dot(batch_eigenvector, ref_eigenvector)))\n",
    "        crit = 30\n",
    "        \n",
    "        if (consecutive):\n",
    "            ref_eigenvector = batch_eigenvector\n",
    "        \n",
    "        deltas.append(measured_angle)\n",
    "        crits.append(crit)\n",
    "        if (measured_angle > crit):\n",
    "            drifts.append(batch + 1)\n",
    "    \n",
    "    y_label = \"SyncStream-PCA\"\n",
    "    if consecutive:\n",
    "        y_label += \" (consecutive)\"\n",
    "    else:\n",
    "        y_label += \" (fixed reference)\"\n",
    "    graph(deltas, crits, y_label)\n",
    "\n",
    "    return drifts\n",
    "    \n",
    "def syncstream_pca(ref_data, test_data, ref_labels=None, encoder=None, scaler=None):\n",
    "    drifts = syncstream_pca_all(ref_data, [test_data], ref_labels, encoder, scaler)\n",
    "    return len(drifts) == 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5f81c6",
   "metadata": {},
   "source": [
    "### SyncStream-Stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46033125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def midrank(Dt, ranks_in_union, start_i, j):\n",
    "    rank_sum = 0\n",
    "    for i in range(start_i, start_i + len(Dt)):\n",
    "        rank_sum += ranks_in_union[i]\n",
    "    return rank_sum / len(Dt)\n",
    "\n",
    "def v2(Dt, u, start_i):\n",
    "    rank_diff_sum = 0\n",
    "    for j in range(Dt.shape[1]):\n",
    "        ranks_in_union = rankdata(u[:, j])\n",
    "        ranks_in_Dt = rankdata(Dt[:, j])\n",
    "        midrank_j = midrank(Dt, ranks_in_union, start_i, j)\n",
    "        for i in range(0, len(Dt)):\n",
    "            rank_diff_sum += (ranks_in_union[start_i + i] - ranks_in_Dt[i] - midrank_j + (len(Dt) + 1) / 2) ** 2\n",
    "    return (1 / (len(Dt) - 1)) * rank_diff_sum\n",
    "\n",
    "def midrank_diff(Dt, Dt1, u, j):\n",
    "    ranks_in_union = rankdata(u[:, j])\n",
    "    return midrank(Dt, ranks_in_union, 0, j) - midrank(Dt1, ranks_in_union, len(Dt), j)\n",
    "\n",
    "def wilcoxon_test(Dt, Dt1, p):\n",
    "    u = np.concatenate((Dt, Dt1))\n",
    "    v2_Dt = v2(Dt, u, 0)\n",
    "    v2_Dt1 = v2(Dt1, u, len(Dt))\n",
    "    var_BF = (len(Dt) + len(Dt1)) * v2_Dt / len(Dt1) + (len(Dt) + len(Dt1)) * v2_Dt1 / len(Dt)\n",
    "    sd_BF = np.sqrt(var_BF)\n",
    "    midrank_diff_sum = 0\n",
    "    for j in range(Dt.shape[1]):\n",
    "        midrank_diff_sum += midrank_diff(Dt, Dt1, u, j)\n",
    "    WBF = np.sqrt(len(Dt) * len(Dt1) / (len(Dt) + len(Dt1))) * midrank_diff_sum / sd_BF\n",
    "    crit = norm.ppf(1-p/2)\n",
    "    return abs(WBF) > crit, abs(WBF), crit\n",
    "\n",
    "def syncstream_stat_all(raw_ref_data, raw_test_batches, ref_labels=None, encoder=None, scaler=None, p=0.01, consecutive=False):\n",
    "    \n",
    "    # Make sure data is in DataFrames\n",
    "    ref_data = ensure_df(raw_ref_data)\n",
    "    test_batches = []\n",
    "    for batch in range(len(raw_test_batches)):\n",
    "        test_batches.append(ensure_df(raw_test_batches[batch]))\n",
    "    \n",
    "    # Encode and scale the data\n",
    "    if encoder:\n",
    "        ref_data, test_batches = encode(ref_data, test_batches, ref_labels, encoder)\n",
    "    if scaler:\n",
    "        ref_data, test_batches = scale(ref_data, test_batches, scaler)\n",
    "    \n",
    "    print(test_batches[0].head())\n",
    "    \n",
    "    deltas = []\n",
    "    crits = []\n",
    "    drifts = []\n",
    "\n",
    "    for batch in range(len(test_batches)):\n",
    "        ref_batch = ref_data\n",
    "        if consecutive and batch != 0:\n",
    "            ref_batch = test_batches[batch - 1]\n",
    "        detected_stat, delta, crit = wilcoxon_test(ref_batch.values, test_batches[batch].values, p)\n",
    "        deltas.append(delta)\n",
    "        crits.append(crit)\n",
    "        if (detected_stat):\n",
    "            drifts.append(batch + 1)\n",
    "    \n",
    "    y_label = \"SyncStream-Stat\"\n",
    "    if consecutive:\n",
    "        y_label += \" (consecutive)\"\n",
    "    else:\n",
    "        y_label += \" (fixed reference)\"\n",
    "    graph(deltas, crits, y_label)\n",
    "    \n",
    "    return drifts\n",
    "\n",
    "def syncstream_stat(ref_data, test_data, ref_labels=None, encoder=None, scaler=None, p=0.01):\n",
    "    drifts = syncstream_stat_all(ref_data, [test_data], ref_labels, encoder, scaler, p)\n",
    "    return len(drifts) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7009827e",
   "metadata": {},
   "source": [
    "### SCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67f9b7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian kernel function\n",
    "\n",
    "# def g_kernel(bandwidth, diff):\n",
    "#     k = len(diff)\n",
    "#     det = np.linalg.det(bandwidth)\n",
    "#     inv = np.linalg.inv(bandwidth)\n",
    "#     exponent_matrix = np.matmul(np.matmul(diff.T, inv), diff)\n",
    "#     return (1 / (np.sqrt(2 * np.pi)**k * np.sqrt(det))) * np.exp((-1 / 2) * exponent_matrix)\n",
    "\n",
    "\n",
    "# Learning bandwidths with Expectation Maximization\n",
    "\n",
    "# def init_bandwidths(n, k):\n",
    "#     print('n', n)\n",
    "#     print('k', k)\n",
    "#     bandwidths = []\n",
    "#     for i in range(n):\n",
    "#         bandwidths.append(np.identity(k))\n",
    "#     return bandwidths\n",
    "\n",
    "# def soft_membership(bandwidth, S1, i, j):\n",
    "#     if i == j:\n",
    "#         return 0\n",
    "#     density_sum = 0\n",
    "#     for t in range(len(S1)):\n",
    "#         if t != j:\n",
    "#             density_sum += g_kernel(bandwidth, S1[j] - S1[t])\n",
    "#     return g_kernel(bandwidth, S1[j] - S1[i]) / density_sum\n",
    "\n",
    "# def bandwidth_update(i, S1, bandwidths):\n",
    "#     nominator_sum = np.zeros((len(S1[0]), len(S1[0])))\n",
    "#     denominator_sum = 0\n",
    "#     for j in range(len(S1)):\n",
    "#         soft_mb = soft_membership(bandwidths[i], S1, i, j)\n",
    "#         point_kernel_diff = S1[j] - S1[i]\n",
    "#         nominator_sum += soft_mb * np.outer(point_kernel_diff, point_kernel_diff.T)\n",
    "#         denominator_sum += soft_mb\n",
    "#     return nominator_sum / denominator_sum\n",
    "\n",
    "# def pseudo_LLH(S1, bandwidths):\n",
    "#     LLH = 0\n",
    "#     for j in range(len(S1)):\n",
    "#         temp_sum = 0\n",
    "#         for i in range(len(S1)):\n",
    "#             if i != j:\n",
    "#                 temp_sum += (1 / (len(S1) - 1)) * g_kernel(bandwidths[i], S1[j] - S1[i])\n",
    "#         LLH += np.log(temp_sum)\n",
    "#     return LLH\n",
    "\n",
    "# def learn_bandwidths(S1, maxIteration, phi):\n",
    "#     bandwidths = init_bandwidths(len(S1), len(S1[0]))\n",
    "#     L = []\n",
    "#     for t in range(maxIteration):\n",
    "#         # compute density for all i, j\n",
    "#         # compute soft membership for all i, j\n",
    "#         # compute new bandwidth for all i\n",
    "#         for i in range(len(bandwidths)):\n",
    "#             bandwidths[i] = bandwidth_update(i, S1, bandwidths)\n",
    "#         # compute L and check for stopping criterion\n",
    "#         L.append(pseudo_LLH(S1, bandwidths))\n",
    "#         print(L[t])\n",
    "#         if t > 0:\n",
    "#             if (((L[t] - L[t - 1]) / L[t - 1]) < phi):\n",
    "#                 break\n",
    "#     return bandwidths\n",
    "\n",
    "\n",
    "# The test statistic\n",
    "\n",
    "# def density_estimate(S1, bandwidths, s):\n",
    "#     density = 0\n",
    "#     for i in range(len(S1)):\n",
    "#         density += (1 / len(S1)) * g_kernel(bandwidths[i], s - S1[i])\n",
    "#     return density\n",
    "\n",
    "# def log_likelihood(bandwidths, S1, data, kde):\n",
    "#     LLH = 0\n",
    "#     for y in range(len(data)):\n",
    "#         LLH += np.log(density_estimate(S1, bandwidths, data[y]))\n",
    "#     return LLH\n",
    "\n",
    "def delta(S1, S2, Sprime, kde):\n",
    "#     return log_likelihood(bandwidths, S1, Sprime, kde) \n",
    "#         - (len(Sprime) / len(S2)) * log_likelihood(bandwidths, S1, S2, kde)\n",
    "    return np.sum(kde.logpdf(Sprime.T)) - (len(Sprime) / len(S2)) * np.sum(kde.logpdf(S2.T)) # drop-in replacement\n",
    "\n",
    "\n",
    "# Determining the critical value\n",
    "    \n",
    "def est_var_estimates(S2, estSize, kde):\n",
    "    est_time = time()\n",
    "    Est = []\n",
    "    std_prev_t = 0.0\n",
    "    for t in range(estSize):\n",
    "        R = resample(S2)\n",
    "#         print(\"resampling done at\", time() - est_var_timer, \"seconds\")\n",
    "#         densities = map(lambda x: np.log(density_estimate(S1, bandwidths, x)), R)\n",
    "        densities = kde.logpdf(R.T) # drop-in replacement\n",
    "#         print(\"densities computed at\", time() - est_var_timer, \"seconds\")\n",
    "        Est.append((len(S2) / (len(S2) - 1)) * variance(densities))\n",
    "        \n",
    "        # stopping criterion after 30 estimates if their SD stabilizes within 1 percent\n",
    "        std_current_t = np.std(Est)\n",
    "        diff_std = float('inf')\n",
    "        if t > 1:\n",
    "            diff_std = abs(std_prev_t - std_current_t) / std_prev_t\n",
    "        print(\"t\", t, \n",
    "              \"mean:\", round(np.mean(Est), 5), \n",
    "              \"std:\", round(std_current_t, 5), \n",
    "              \"diff_std:\", round(diff_std, 5), \n",
    "              \"time:\", time() - est_time\n",
    "             )\n",
    "        if t >= 29 and diff_std < 0.01:\n",
    "            break\n",
    "        std_prev_t = std_current_t\n",
    "        \n",
    "    Est.sort()\n",
    "    return Est\n",
    "\n",
    "def critical_value(p, stepSize, S2_size, Sprime_size, kde, Est):\n",
    "    M = math.floor(p / stepSize - 1)\n",
    "    C = []\n",
    "    for i in range(M):\n",
    "        alpha = (i + 1) * stepSize\n",
    "        beta = p - alpha\n",
    "        # estimate variance for this beta:\n",
    "        upper_limit = Est[math.ceil((len(Est) * (1 - beta) - 1))]\n",
    "        var = (Sprime_size + Sprime_size**2/S2_size) * upper_limit\n",
    "        # find c such that P(D <= c) = alpha, D ~ N(0, var):\n",
    "        D = norm(0, np.sqrt(var))\n",
    "        c = D.ppf(alpha)\n",
    "        C.append(c)\n",
    "    Cmax = np.amin(C)\n",
    "    return Cmax\n",
    "\n",
    "\n",
    "# Full procedure\n",
    "\n",
    "def density_test(S1, S2, Sprime, p, kde, Est):\n",
    "    # Calculate delta between S2 and S'\n",
    "    d = delta(S1, S2, Sprime, kde)\n",
    "    # Get critical value from S2\n",
    "    stepSize = 0.002\n",
    "    c = critical_value(p, stepSize, len(S2), len(Sprime), kde, Est)\n",
    "    # Report drift if delta < critical value\n",
    "    return d < c, d, c\n",
    "\n",
    "def scd_all(raw_ref_data, raw_test_batches, ref_labels=None, encoder=None, scaler=None, p=0.08, bidirectional=False):\n",
    "    \n",
    "    # Make sure data is in DataFrames\n",
    "    ref_data = ensure_df(raw_ref_data)\n",
    "    test_batches = []\n",
    "    for batch in range(len(raw_test_batches)):\n",
    "        test_batches.append(ensure_df(raw_test_batches[batch]))\n",
    "    \n",
    "    # Encode and scale the data\n",
    "    if encoder:\n",
    "        ref_data, test_batches = encode(ref_data, test_batches, ref_labels, encoder)\n",
    "    if scaler:\n",
    "        ref_data, test_batches = scale(ref_data, test_batches, scaler)\n",
    "        \n",
    "    print(test_batches[0].head())\n",
    "    \n",
    "    # Randomly partition the training set S into S1 and S2\n",
    "    S1, S2 = train_test_split(ref_data, train_size=0.50, shuffle=True)\n",
    "    \n",
    "    # Use EM to learn the kernel model over S1\n",
    "#     bandwidths = learn_bandwidths(S1.to_numpy(), maxIteration=100, phi=0.01)\n",
    "    kde = gaussian_kde(S1.to_numpy().T) # drop-in replacement\n",
    "    \n",
    "    # Estimate the variance\n",
    "    estSize = 4000\n",
    "    Est = est_var_estimates(S2.to_numpy(), estSize, kde)\n",
    "    \n",
    "    deltas = []\n",
    "    crits = []\n",
    "    deltas_reverse = []\n",
    "    crits_reverse = []\n",
    "    drifts = []\n",
    "    \n",
    "    # Consider each test batch S':\n",
    "    for batch in range(len(test_batches)):\n",
    "        p_value = p\n",
    "        if bidirectional:\n",
    "            p_value = p/2\n",
    "            \n",
    "        detected_scd, delta, crit = density_test(\n",
    "            S1.to_numpy(), \n",
    "            S2.to_numpy(), \n",
    "            test_batches[batch].to_numpy(), \n",
    "            p_value, \n",
    "            kde, \n",
    "            Est\n",
    "        )\n",
    "        deltas.append(delta)\n",
    "        deltas_reverse.append(0)\n",
    "        crits.append(crit)\n",
    "        crits_reverse.append(0)\n",
    "        if detected_scd:\n",
    "            drifts.append(batch + 1)\n",
    "            \n",
    "        # If no drift was detected, run again with S and S' reversed\n",
    "        elif bidirectional:\n",
    "            print(\"Running in reverse for batch\", batch)\n",
    "            S1_reverse, S2_reverse = train_test_split(test_batches[batch], train_size=0.50, shuffle=True)\n",
    "            \n",
    "            # Use EM to learn the kernel model over S1\n",
    "        #     bandwidths = learn_bandwidths(S1.to_numpy(), maxIteration=100, phi=0.01)\n",
    "            kde_reverse = gaussian_kde(S1_reverse.to_numpy().T) # drop-in replacement\n",
    "            \n",
    "            # Estimate the variance\n",
    "            Est_reverse = est_var_estimates(S2_reverse.to_numpy(), estSize, kde_reverse)\n",
    "            \n",
    "            detected_scd_reverse, delta_reverse, crit_reverse = density_test(\n",
    "                S1_reverse.to_numpy(), \n",
    "                S2_reverse.to_numpy(), \n",
    "                ref_data.to_numpy(), \n",
    "                p_value, \n",
    "                kde_reverse, \n",
    "                Est_reverse\n",
    "            )\n",
    "            deltas_reverse[batch] = delta_reverse\n",
    "            crits_reverse[batch] = crit_reverse\n",
    "            if detected_scd_reverse:\n",
    "                drifts.append(batch + 1)\n",
    "    \n",
    "    y_label = \"SCD\"\n",
    "    if bidirectional:\n",
    "        y_label += \" (bidirectional)\"\n",
    "        graph(deltas, crits, y_label, deltas_reverse, crits_reverse)\n",
    "    else:\n",
    "        y_label += \" (unidirectional)\"\n",
    "        graph(deltas, crits, y_label)\n",
    "    \n",
    "            \n",
    "    return drifts\n",
    "\n",
    "def scd(ref_data, test_data, ref_labels=None, encoder=None, scaler=None, p=0.08, bidirectional=False):\n",
    "    drifts = scd_all(ref_data, [test_data], ref_labels, encoder, scaler, p, bidirectional)\n",
    "    return len(drifts) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4cb913",
   "metadata": {},
   "source": [
    "### Classifier detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1611709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def est_crit_random_cross_val(model, ref_data):\n",
    "    # Estimate accuracy variance by running cross-validation on randomly labeled ref data n times\n",
    "    ref_accs = []\n",
    "    half_point_ref_data = int(len(ref_data) / 2)\n",
    "    ref_zero_labels = np.zeros(half_point_ref_data)\n",
    "    ref_one_labels = np.ones(len(ref_data) - half_point_ref_data)\n",
    "    ref_labels = np.concatenate([ref_zero_labels, ref_one_labels])\n",
    "    for n in range(10):\n",
    "        np.random.shuffle(ref_labels)\n",
    "        score = cross_val_score(model, ref_data, ref_labels, cv=5).mean()\n",
    "#         print(score)\n",
    "        ref_accs.append(score)\n",
    "#     print(ref_accs)\n",
    "    print(np.std(ref_accs))\n",
    "    crit = 0.5 + 2 * np.std(ref_accs)\n",
    "    return crit\n",
    "\n",
    "def classifier_detector_all(raw_ref_data, raw_test_batches, ref_labels=None, encoder=None, scaler=None, pca_preprocess=False):\n",
    "    # Make sure data is in DataFrames\n",
    "    ref_data = ensure_df(raw_ref_data)\n",
    "    test_batches = []\n",
    "    for batch in range(len(raw_test_batches)):\n",
    "        test_batches.append(ensure_df(raw_test_batches[batch]))\n",
    "    \n",
    "    # Encode and scale the data\n",
    "    if encoder:\n",
    "        ref_data, test_batches = encode(ref_data, test_batches, ref_labels, encoder)\n",
    "    if scaler:\n",
    "        ref_data, test_batches = scale(ref_data, test_batches, scaler)\n",
    "        \n",
    "    if pca_preprocess:\n",
    "        print(\"preprocessing with PCA\")\n",
    "        pca = PCA()\n",
    "        ref_data = pd.DataFrame(pca.fit_transform(ref_data))\n",
    "        preprocessed_test_batches = []\n",
    "        for batch in range(len(test_batches)):\n",
    "            preprocessed_test_batches.append(pd.DataFrame(pca.transform(test_batches[batch])))\n",
    "        test_batches = preprocessed_test_batches\n",
    "        \n",
    "#     print(test_batches[0].head())\n",
    "\n",
    "    # Make a model\n",
    "    n_neighbors = int(len(test_batches[0]) / 10)\n",
    "    model = KNeighborsClassifier(n_neighbors)\n",
    "    \n",
    "    # Take equal-sized tail of ref data to go with the test batches\n",
    "    last_ref_batch = ref_data.tail(len(test_batches[0]))\n",
    "    print(len(ref_data))\n",
    "    \n",
    "    # Estimate critical value\n",
    "    crit = est_crit_random_cross_val(model, ref_data)\n",
    "    \n",
    "#     print(\"crit\", crit, \"\\n\")\n",
    "    \n",
    "    \n",
    "    # See how well the model can tell apart the last ref batch from other random picks of the ref data\n",
    "\n",
    "    i = 0\n",
    "    while i < len(X_test):\n",
    "        new_i = i + 17000\n",
    "        if new_i > len(X_test):\n",
    "            new_i = len(X_test)\n",
    "        X_test_batches.append(X_test[i: new_i])\n",
    "        y_test_batches.append(y_test[i: new_i])\n",
    "        i = new_i\n",
    "    \n",
    "    \n",
    "    # For each test batch, label it with ones, lump it together with reference data (labeled zeros)\n",
    "    # and train a classifier on that.\n",
    "    accuracies = []\n",
    "    crits = []\n",
    "    drifts = []\n",
    "    for batch in range(len(test_batches)):\n",
    "        zero_labels = np.zeros(len(last_ref_batch))\n",
    "        one_labels = np.ones(len(test_batches[batch]))\n",
    "        X = np.concatenate([last_ref_batch.values, test_batches[batch].values])\n",
    "        y = np.concatenate([zero_labels, one_labels])\n",
    "        score = cross_val_score(model, X, y, cv=5).mean()\n",
    "#         print(score)\n",
    "        accuracies.append(score)\n",
    "        crits.append(crit)\n",
    "        if (score > crit):\n",
    "            drifts.append(batch + 1)\n",
    "            \n",
    "    \n",
    "    # Cross-validation accuracy of the classifier is our test statistic:\n",
    "    # too high accuracy means the model is able to separate the batches.\n",
    "    graph(accuracies, crits, \"Classifier detector\")\n",
    "    \n",
    "    return drifts\n",
    "\n",
    "def classifier_detector(ref_data, test_data, ref_labels=None, encoder=None, scaler=None, pca_preprocess=False):\n",
    "    drifts = classifier_detector_all(ref_data, [test_data], ref_labels, encoder, scaler, pca_preprocess)\n",
    "    return len(drifts) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af83247b",
   "metadata": {},
   "source": [
    "### Run synthetic datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b603ff6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def run_detectors(X_train, X_test, y_train, filename, real_drift, n_batches, encoder, scaler, pca_preprocess=False):\n",
    "    ref_data = X_train\n",
    "    test_batches = np.array_split(X_test, n_batches)\n",
    "    ref_labels = y_train\n",
    "    \n",
    "#     timer = time()\n",
    "#     drifts_pca_ref = syncstream_pca_all(ref_data, test_batches, ref_labels, encoder, scaler)\n",
    "#     print(\"syncstream_pca_all took\", time() - timer, \"seconds\")\n",
    "    \n",
    "#     timer = time()\n",
    "#     drifts_stat_ref = syncstream_stat_all(ref_data, test_batches, ref_labels, encoder, scaler)\n",
    "#     print(\"syncstream_stat_all took\", time() - timer, \"seconds\")\n",
    "    \n",
    "#     drifts_scd_unidir = []\n",
    "#     if encoder != \"onehot\": # due to matrix errors\n",
    "#         timer = time()\n",
    "#         drifts_scd_unidir = scd_all(ref_data, test_batches, ref_labels, encoder, scaler)\n",
    "#         print(\"scd_all took\", time() - timer, \"seconds\")\n",
    "        \n",
    "#     timer = time()\n",
    "#     drifts_pca_orig = syncstream_pca_all(ref_data, test_batches, ref_labels, encoder, scaler, consecutive=True)\n",
    "#     print(\"syncstream_pca_all (cons) took\", time() - timer, \"seconds\")\n",
    "    \n",
    "#     timer = time()\n",
    "#     drifts_stat_orig = syncstream_stat_all(ref_data, test_batches, ref_labels, encoder, scaler, consecutive=True)\n",
    "#     print(\"syncstream_stat_all (cons) took\", time() - timer, \"seconds\")\n",
    "\n",
    "#     drifts_scd_bidir = []\n",
    "#     if encoder != \"onehot\": # due to matrix errors\n",
    "#         drifts_scd_bidir = scd_all(ref_data, test_batches, ref_labels, encoder, scaler, bidirectional=True)\n",
    "\n",
    "    timer = time()\n",
    "    drifts_classifier = classifier_detector_all(ref_data, test_batches, ref_labels, encoder, scaler, pca_preprocess)\n",
    "    print(\"classifier_detector_all took\", time() - timer, \"seconds\")\n",
    "    \n",
    "    print(\"\\n\", filename, \"encoder:\", encoder, \"scaler:\", scaler, \"PCA preprocess:\", pca_preprocess)\n",
    "    report_1 = [\n",
    "#         \"PCA_ref:\",\n",
    "#         drifts_pca_ref,\n",
    "#         postprocess(real_drift, drifts_pca_ref, n_batches),\n",
    "#         \"Stat_ref:\",\n",
    "#         drifts_stat_ref,\n",
    "#         postprocess(real_drift, drifts_stat_ref, n_batches),\n",
    "#         \"SCD_unidir:\",\n",
    "#         drifts_scd_unidir,\n",
    "#         postprocess(real_drift, drifts_scd_unidir, n_batches),\n",
    "        \"Classifier:\",\n",
    "        drifts_classifier,\n",
    "        postprocess(real_drift, drifts_classifier, n_batches)\n",
    "    ]\n",
    "    report_2 = [\n",
    "#         \"PCA_orig:\",\n",
    "#         drifts_pca_orig,\n",
    "#         postprocess(real_drift, drifts_pca_orig, n_batches),\n",
    "#         \"Stat_orig:\",\n",
    "#         drifts_stat_orig,\n",
    "#         postprocess(real_drift, drifts_stat_orig, n_batches),\n",
    "#         \"SCD_bidir:\",\n",
    "#         drifts_scd_bidir,\n",
    "#         postprocess(real_drift, drifts_scd_bidir, n_batches)\n",
    "    ]\n",
    "    \n",
    "    print(*report_1)\n",
    "    print(*report_2, \"\\n\")\n",
    "    \n",
    "\n",
    "SEA_filenames = [\n",
    "#     \"synthetic_data/abrupt_drift/sea_1_abrupt_drift_0_noise_balanced.arff\",\n",
    "#     \"synthetic_data/gradual_drift/sea_1_gradual_drift_0_noise_balanced_1.arff\",\n",
    "#     \"synthetic_data/gradual_drift/sea_1_gradual_drift_0_noise_balanced_5.arff\",\n",
    "#     \"synthetic_data/gradual_drift/sea_1_gradual_drift_0_noise_balanced_05.arff\",\n",
    "#     \"synthetic_data/gradual_drift/sea_1_gradual_drift_0_noise_balanced_10.arff\",\n",
    "#     \"synthetic_data/gradual_drift/sea_1_gradual_drift_0_noise_balanced_20.arff\"\n",
    "]\n",
    "\n",
    "for filename in SEA_filenames:\n",
    "    X_train, X_test = read_sea(filename)\n",
    "    run_detectors(X_train, X_test, None, filename, real_drift=3, n_batches=7, encoder=None, scaler=None)\n",
    "    run_detectors(X_train, X_test, None, filename, real_drift=3, n_batches=7, encoder=None, scaler=\"minmax\")\n",
    "    run_detectors(X_train, X_test, None, filename, real_drift=3, n_batches=7, encoder=None, scaler=None, pca_preprocess=True)\n",
    "    run_detectors(X_train, X_test, None, filename, real_drift=3, n_batches=7, encoder=None, scaler=\"minmax\", pca_preprocess=True)\n",
    "    \n",
    "AGRAW_filenames = [\n",
    "#     \"synthetic_data/abrupt_drift/agraw1_1_abrupt_drift_0_noise_balanced.arff\",\n",
    "#     \"synthetic_data/gradual_drift/agraw1_1_gradual_drift_0_noise_balanced_1.arff\",\n",
    "#     \"synthetic_data/gradual_drift/agraw1_1_gradual_drift_0_noise_balanced_5.arff\",\n",
    "#     \"synthetic_data/gradual_drift/agraw1_1_gradual_drift_0_noise_balanced_05.arff\",\n",
    "#     \"synthetic_data/gradual_drift/agraw1_1_gradual_drift_0_noise_balanced_10.arff\",\n",
    "#     \"synthetic_data/gradual_drift/agraw1_1_gradual_drift_0_noise_balanced_20.arff\",\n",
    "#     \"synthetic_data/abrupt_drift/agraw2_1_abrupt_drift_0_noise_balanced.arff\",\n",
    "#     \"synthetic_data/gradual_drift/agraw2_1_gradual_drift_0_noise_balanced_1.arff\",\n",
    "#     \"synthetic_data/gradual_drift/agraw2_1_gradual_drift_0_noise_balanced_5.arff\",\n",
    "#     \"synthetic_data/gradual_drift/agraw2_1_gradual_drift_0_noise_balanced_05.arff\",\n",
    "#     \"synthetic_data/gradual_drift/agraw2_1_gradual_drift_0_noise_balanced_10.arff\",\n",
    "#     \"synthetic_data/gradual_drift/agraw2_1_gradual_drift_0_noise_balanced_20.arff\"\n",
    "]\n",
    "\n",
    "for filename in AGRAW_filenames:\n",
    "    X_train, X_test, y_train, y_test = read_agraw(filename)\n",
    "    print(X_train)\n",
    "    run_detectors(X_train, X_test, y_train, filename, real_drift=3, n_batches=7, encoder=\"onehot\", scaler=None)\n",
    "    run_detectors(X_train, X_test, y_train, filename, real_drift=3, n_batches=7, encoder=\"onehot\", scaler=\"minmax\")\n",
    "    run_detectors(X_train, X_test, y_train, filename, real_drift=3, n_batches=7, encoder=\"ordinal\", scaler=None)\n",
    "    run_detectors(X_train, X_test, y_train, filename, real_drift=3, n_batches=7, encoder=\"ordinal\", scaler=\"minmax\")\n",
    "    run_detectors(X_train, X_test, y_train, filename, real_drift=3, n_batches=7, encoder=\"target\", scaler=None)\n",
    "    run_detectors(X_train, X_test, y_train, filename, real_drift=3, n_batches=7, encoder=\"target\", scaler=\"minmax\")\n",
    "    run_detectors(X_train, X_test, y_train, filename, real_drift=3, n_batches=7, encoder=\"onehot\", scaler=None, pca_preprocess=True)\n",
    "    run_detectors(X_train, X_test, y_train, filename, real_drift=3, n_batches=7, encoder=\"onehot\", scaler=\"minmax\", pca_preprocess=True)\n",
    "    run_detectors(X_train, X_test, y_train, filename, real_drift=3, n_batches=7, encoder=\"ordinal\", scaler=None, pca_preprocess=True)\n",
    "    run_detectors(X_train, X_test, y_train, filename, real_drift=3, n_batches=7, encoder=\"ordinal\", scaler=\"minmax\", pca_preprocess=True)\n",
    "    run_detectors(X_train, X_test, y_train, filename, real_drift=3, n_batches=7, encoder=\"target\", scaler=None, pca_preprocess=True)\n",
    "    run_detectors(X_train, X_test, y_train, filename, real_drift=3, n_batches=7, encoder=\"target\", scaler=\"minmax\", pca_preprocess=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180b5da0",
   "metadata": {},
   "source": [
    "### Run real-world datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1394bc5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007807214145917144\n",
      "crit 0.5156144282918342 \n",
      "\n",
      "365\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier_detector_all took 14.51411771774292 seconds\n",
      "\n",
      " real_world_data/electricity_dataset.csv encoder: None scaler: minmax PCA preprocess: False\n",
      "Classifier: [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83] (0.7407407407407407, 0.9107142857142857)\n",
      "\n",
      "\n",
      "preprocessing with PCA\n",
      "0.004312543142248449\n",
      "crit 0.5086250862844969 \n",
      "\n",
      "365\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAwGElEQVR4nO3de1xVdb7/8fcW5OIFvJAoSoi3ESVToMxbTjcUTbOxQpuymm40OaacLprHC5bRaRp1LC/H0jyaJcdLTjWciqzxWmOiGJWjlSRmEKkzoFmosH5/+HOPO0D3gr3dm6+v5+OxHo/2d3/X2p+91k7ej++6fB2WZVkCAAAwRANfFwAAAOBJhBsAAGAUwg0AADAK4QYAABiFcAMAAIxCuAEAAEYh3AAAAKME+rqAC62yslLfffedmjZtKofD4etyAACAGyzL0tGjRxUVFaUGDc49NnPRhZvvvvtO0dHRvi4DAADUwoEDB9SuXbtz9rnowk3Tpk0lnd45YWFhPq4GAAC4o6ysTNHR0c6/4+dy0YWbM6eiwsLCCDcAANQz7lxSwgXFAADAKIQbAABgFMINAAAwCuEGAAAYhXADAACMQrgBAABGIdwAAACjEG4AAIBRCDcAAMAohBsAAGAUwg0AADCKT8PNxo0bNWzYMEVFRcnhcGjdunXnXWfDhg1KTExUSEiIOnTooIULF3q/UAAAUG/4NNz8+OOPuvzyy/Xiiy+61b+goEBDhgzRgAEDtHPnTj355JMaN26c1qxZ4+VKAQBAfeHTWcFTUlKUkpLidv+FCxfq0ksv1Zw5cyRJcXFx2r59u55//nmNHDnSS1UCAID6pF5dc/PRRx8pOTnZpW3QoEHavn27Tp48We065eXlKisrc1kAAIC56lW4KS4uVmRkpEtbZGSkTp06pUOHDlW7TmZmpsLDw51LdHT0hSgVgIc4HP9eqmv3ZN/zre+tvr76vnb6+mrfsB/r/370hXoVbiTJ8Yu9ZllWte1nTJo0SaWlpc7lwIEDXq8RAAD4jk+vubGrdevWKi4udmkrKSlRYGCgWrZsWe06wcHBCg4OvhDlAQAAP1CvRm769OmjnJwcl7b33ntPSUlJatiwoY+qAgAA/sSn4ebYsWPKy8tTXl6epNO3eufl5amwsFDS6VNKY8aMcfZPS0vT/v37lZ6ert27d2vJkiVavHixHn30UV+UDwAA/JBPT0tt375d11xzjfN1enq6JOmuu+7S0qVLVVRU5Aw6khQbG6vs7GxNmDBB8+bNU1RUlObOnctt4AAAwMlhnbki9yJRVlam8PBwlZaWKiwszNflADiPs+8VOPtfqzPt1bXVtu/51vdWX09+B2/19dW+sdOX/eiZvp7eN55i5+93vbrmBgAA4HwINwAAwCiEGwAAYBTCDQAAMArhBgAAGIVwAwAAjEK4AQAARiHcAAAAoxBuAACAUQg3AADAKIQbAABgFMINAAAwCuEGAAAYhXADAACMQrgBAABGIdwAAACjEG4AAIBRCDcAAMAohBsAAGAUwg0Ar3I4Ti8AcKEQbgAAgFEINwAAwCiEGwAAYBTCDQAAMArhBgAAGIVwAwAAjEK4AeA3uG0cgCcQbgAAgFEINwAAwCiBvi4AqM7ZpyYsy3d1AADqH0ZuAACAUQg3AADAKIQbAABgFMINAAAwCuEGAAAYhXADAACMQrgBAABG4Tk3qBOeRwMA8DeM3AAAAKMQbgAAgFE4LQXgguN0JgBvYuQGAAAYhXADAACMQrgBAABGIdwAAACjEG4AAIBRCDcAAMAohBsAAGAUwg0AADAK4QYAABiFcAMAAIxCuAEAAEYh3AAAAKMQbgAAgFGYFRw+xezQAABPY+QGXuFwuAYXAAAuFMINAAAwCuEGAAAYhXADAACMQrgBAABG8Xm4mT9/vmJjYxUSEqLExERt2rTpnP1XrFihyy+/XI0aNVKbNm10zz336PDhwxeoWgAA4O98Gm6ysrI0fvx4TZ48WTt37tSAAQOUkpKiwsLCavtv3rxZY8aM0b333qvPP/9cq1at0ieffKL77rvvAlcOAAD8lU/DzaxZs3TvvffqvvvuU1xcnObMmaPo6GgtWLCg2v4ff/yx2rdvr3Hjxik2Nlb9+/fXgw8+qO3bt9f4GeXl5SorK3NZ4Btnbg/nFnEAgDf5LNycOHFCubm5Sk5OdmlPTk7W1q1bq12nb9+++vbbb5WdnS3LsvT9999r9erVGjp0aI2fk5mZqfDwcOcSHR3t0e8BAAD8i8/CzaFDh1RRUaHIyEiX9sjISBUXF1e7Tt++fbVixQqlpqYqKChIrVu3VrNmzfTCCy/U+DmTJk1SaWmpczlw4IBHvwcuHEZ+/BvHB4C/8PkFxY5f/EtoWVaVtjO++OILjRs3TlOnTlVubq7eeecdFRQUKC0trcbtBwcHKywszGUB3MEfagCon3w2t1RERIQCAgKqjNKUlJRUGc05IzMzU/369dNjjz0mSerRo4caN26sAQMG6Omnn1abNm28XjfqB+asAoCLl89GboKCgpSYmKicnByX9pycHPXt27fadY4fP64GDVxLDggIkHR6xAcAAMCnp6XS09P18ssva8mSJdq9e7cmTJigwsJC52mmSZMmacyYMc7+w4YN09q1a7VgwQLt27dPW7Zs0bhx43TllVcqKirKV18DAAD4EZ+dlpKk1NRUHT58WDNmzFBRUZHi4+OVnZ2tmJgYSVJRUZHLM2/uvvtuHT16VC+++KL+4z/+Q82aNdO1116r//qv//LVV7ionDnVwyAZAMCfOayL7HxOWVmZwsPDVVpaysXFNlUXbmq6tsXdvudb352+56rVnb7n28bF9X9I7dX1t+APfT3xe6xNX/aNZ/qyHz3T19P7xlPs/P32+d1SAAAAnkS4AQAARiHcAAAAoxBuAACAUXx6txTgD3jgHwCYhZEbAABgFMINAAAwCqelABs4hQUA/o+RGwAAYBTCDQAAMArhBgAAGIVwAwAAjMIFxQBs48JqAP6MkRsAAGAUwg0AADAK4QYAABiFcAMAAIxCuAEAAEYh3AAAAKMQbgAAgFEINwAAwCiEGwAAYBSeUIx6j6flAgDOxsgNAAAwCuEGAAAYhXADAACMQrgBAABGsRVuTp48qXvuuUf79u3zVj0AAAB1YivcNGzYUG+88Ya3agHqLYfD9a4tAIDv2D4tdfPNN2vdunVeKAUAAKDubD/nplOnTnrqqae0detWJSYmqnHjxi7vjxs3zmPFAQAA2OWwLHuPPYuNja15Yw6H31+PU1ZWpvDwcJWWliosLMzX5dQrZ067nP2LqekBeu72Pd/6nu5bnbp+h5r6mqw2x8eTvxtv9b3Qv0dff187fX21b+z0ZT96pq+n942n2Pn7bXvkpqCgoNaFAQAAeFudbgW3LEs2B34AAAC8qlbhZtmyZbrssssUGhqq0NBQ9ejRQ8uXL/d0bQAAALbZPi01a9YsTZkyRWPHjlW/fv1kWZa2bNmitLQ0HTp0SBMmTPBGnQAAAG6xHW5eeOEFLViwQGPGjHG23XTTTerevbumT59OuDEAs2wDAOoz26elioqK1Ldv3yrtffv2VVFRkUeKAgAAqC3b4aZTp0763//93yrtWVlZ6ty5s0eKAgAAqC3bp6UyMjKUmpqqjRs3ql+/fnI4HNq8ebPWr19fbegBUH9xihJAfWR75GbkyJH6+9//roiICK1bt05r165VRESEtm3bpptvvtkbNQIAALjN9siNJCUmJurVV1/1dC0AAAB1ZnvkJiAgQCUlJVXaDx8+rICAAI8UBQAAUFu2w01NTyQuLy9XUFBQnQsCAACoC7dPS82dO1fS6ckxX375ZTVp0sT5XkVFhTZu3KiuXbt6vkIAAAAb3A43s2fPlnR65GbhwoUup6CCgoLUvn17LVy40PMVAgAA2OB2uDkzG/g111yjtWvXqnnz5l4rCgAAoLZs3y314YcfeqMOAAAAj7B9QfEtt9yiZ599tkr7H//4R916660eKQrwFofj3wsAwEy2w82GDRs0dOjQKu2DBw/Wxo0bPVIUAABAbdkON8eOHav2lu+GDRuqrKzMI0UBAADUlu1wEx8fr6ysrCrtK1euVLdu3TxSFAAAQG3ZvqB4ypQpGjlypL7++mtde+21kqT169fr9ddf16pVqzxeIAAAgB22w83w4cO1bt06PfPMM1q9erVCQ0PVo0cPvf/++xo4cKA3agQAAHBbrSbOHDp0aLUXFQOov86+g6yGWVYAoF6wfc2NJP3rX//Syy+/rCeffFJHjhyRJO3YsUMHDx70aHEAAAB22R65+fTTT3X99dcrPDxc33zzje677z61aNFCb7zxhvbv369ly5Z5o04AAAC32B65SU9P1913360vv/xSISEhzvaUlBSecwMAAHzOdrj55JNP9OCDD1Zpb9u2rYqLiz1SFAAAQG3ZDjchISHVPqxvz549uuSSS2wXMH/+fMXGxiokJESJiYnatGnTOfuXl5dr8uTJiomJUXBwsDp27KglS5bY/lwAAGAm2+Hmpptu0owZM3Ty5ElJksPhUGFhoSZOnKiRI0fa2lZWVpbGjx+vyZMna+fOnRowYIBSUlJUWFhY4zq33Xab1q9fr8WLF2vPnj16/fXX1bVrV7tfAwAAGMphWfZu+iwrK9OQIUP0+eef6+jRo4qKilJxcbH69Omj7OxsNW7c2O1t9e7dWwkJCVqwYIGzLS4uTiNGjFBmZmaV/u+8845GjRqlffv2qUWLFnbKdqk/PDxcpaWlCgsLq9U2TFfTLcFn2qtrq23f863vD31r+33rG3/djxfD75F945m+7EfP9PX0vvEUO3+/bd8tFRYWps2bN+uDDz7Qjh07VFlZqYSEBF1//fW2tnPixAnl5uZq4sSJLu3JycnaunVrteu8+eabSkpK0nPPPafly5ercePGGj58uJ566imFhoZWu055ebnKy8udr5n/CgAAs9kON8uWLVNqaqquvfZa5/QL0umwsnLlSo0ZM8at7Rw6dEgVFRWKjIx0aY+MjKzxwuR9+/Zp8+bNCgkJ0RtvvKFDhw7p97//vY4cOVLjdTeZmZnKyMhw89sB/o+H7QHAudm+5uaee+5RaWlplfajR4/qnnvusV2A4+x/qSVZllWl7YzKyko5HA6tWLFCV155pYYMGaJZs2Zp6dKl+umnn6pdZ9KkSSotLXUuBw4csF0jAACoP2yP3NQUPr799luFh4e7vZ2IiAgFBARUGaUpKSmpMppzRps2bdS2bVuXz4mLi5NlWfr222/VuXPnKusEBwcrODjY7boAkzDKA+Bi5Ha46dWrlxwOhxwOh6677joFBv571YqKChUUFGjw4MFuf3BQUJASExOVk5Ojm2++2dmek5Ojm266qdp1+vXrp1WrVunYsWNq0qSJJGnv3r1q0KCB2rVr5/ZnAwAAc7kdbkaMGCFJysvL06BBg5zhQjodVNq3b2/7VvD09HTdeeedSkpKUp8+fbRo0SIVFhYqLS1N0ulTSgcPHnRO6XD77bfrqaee0j333KOMjAwdOnRIjz32mH73u9/VeEExAAC4uLgdbqZNmyZJat++vVJTU12mXqit1NRUHT58WDNmzFBRUZHi4+OVnZ2tmJgYSVJRUZHLM2+aNGminJwc/eEPf1BSUpJatmyp2267TU8//XSdawEAAGaw/Zwb6fSs4KtXr9bXX3+txx57TC1atNCOHTsUGRmptm3beqNOj+E5N+fHMx/sfYea+nqLneto6trXH/bjxfB7ZN94pi/70TN9L8rn3PxyVvD777+fWcEBAIDfsH0r+IQJE5gVHAAA+C3bIzfbt2/XokWLqrQzKzgAAPAHPp8VHAAAwJN8Ois4AACAp9kON88//7x++OEHtWrVSj/99JMGDhyoTp06qWnTppo5c6Y3agQAAHCbz2YFBwAA8Abb4eaMX84KDsAV8zoBgG+4FW7mzp3r9gbHjRtX62IAAADqyq1wM3v2bJfXP/zwg44fP65mzZpJOv3E4kaNGqlVq1aEGwAA4FNuXVBcUFDgXGbOnKmePXtq9+7dOnLkiI4cOaLdu3crISFBTz31lLfrBQAAOCfbc0t17NhRq1evVq9evVzac3Nzdcstt6igoMCjBXoac0udH/Os2PsOdvvaUdftMreUvb6m/MZM2jd2+rIfPdPXhLmlbN8KXlRU5HzGzdkqKir0/fff290cAACAR9kON9ddd53uv/9+bd++XWcGfbZv364HH3yQ28EBAIDP2Q43S5YsUdu2bXXllVcqJCREwcHB6t27t9q0aaOXX37ZGzUCAAC4zfZzbi655BJlZ2fryy+/1O7du2VZluLi4tSlSxdv1AcAAGBLrR/i17lzZ3Xu3NmTtQAAANSZ7dNSAAAA/oxwAwAAjFLr01IA6ifmvAJgOlsjN6dOnVJGRoYOHDjgrXoAAADqxFa4CQwM1B//+EdVVFR4qx4AAIA6sX3NzfXXX6+//e1vXigFAACg7mxfc5OSkqJJkybps88+U2Jioho3buzy/vDhwz1WXL1jWdLx476uolqNm/z7v388du6+jc5+8WM17dW11bLvedf3h74e/L521XW7Ju9Ho36P7BvP9GU/eqZvHb/vcTWSdNbFfT5ge+LMBg1qHuxxOBx+f8rKqxNn/vij1KTJ+fsBAGCoxjqmH63G5+9ok52/37ZHbiorK2tdGAAAgLfV6Vbwn3/+WSEhIZ6qpf5r1Eg6dp5zPj5S02mpM+3VtV2Ivudb3x/6enrf2FHX7Zq8H036PbJvPNOX/eiZvnX9vsddT2b5hO3TUhUVFXrmmWe0cOFCff/999q7d686dOigKVOmqH379rr33nu9VatHePW0lB+r6dkmZ9qra7sQfc+3vj/09fS+saOu2zV5P5r0e2TfeKYv+9EzfX35b9652Pn7bftuqZkzZ2rp0qV67rnnFBQU5Gy/7LLLmBUcAAD4nO1ws2zZMi1atEi//e1vFRAQ4Gzv0aOH/vGPf3i0OADucTj+vQDAxc52uDl48KA6depUpb2yslInT570SFEAAAC1ZTvcdO/eXZs2barSvmrVKvXq1csjRQEAANSW7bulpk2bpjvvvFMHDx5UZWWl1q5dqz179mjZsmV6++23vVEjAACA22yP3AwbNkxZWVnKzs6Ww+HQ1KlTtXv3br311lu64YYbvFEjAACA22r1nJtBgwZp0KBBnq4FAACgzmyP3AAAAPgzt0ZuWrRoob179yoiIkLNmzeX4xz3mx45csRjxQEAANjlVriZPXu2mjZtKkmaM2eON+sBAACoE7fCza5du3TLLbcoODhYsbGx6tu3rwID6zQtFQAAgFe4dc3NCy+8oGP/f0LIa665hlNPAADAb7k1/NK+fXvNnTtXycnJsixLH330kZo3b15t36uvvtqjBQIAANjh1qzg69atU1pamkpKSuRwOFTTKg6HQxUVFR4v0pOYFZwZcu32rQ+zgl+M+9Gk3yP7xjN92Y+e6WvCrOBujdyMGDFCI0aM0LFjxxQWFqY9e/aoVatWHikWAADAk2xdFdykSRN9+OGHio2N5YJiAADgl9xKKGVlZc4hoF69eun48eM19r2YTvUAAAD/41a4ad68uYqKitSqVSs1a9as2of4WZZVL665AQAAZnMr3HzwwQdq0aKFJOnDDz/0akEAAAB14Va4GThwYLX/DQAA4G9sT5z5zjvvaPPmzc7X8+bNU8+ePXX77bfrn//8p0eLAwAAsMt2uHnsscdUVlYmScrPz1d6erqGDBmiffv2KT093eMFAgAA2GH7fu6CggJ169ZNkrRmzRoNGzZMzzzzjHbs2KEhQ4Z4vEDANNU9/AoA4Dm2R26CgoKct4K///77Sk5OliS1aNHCOaIDAADgK7ZHbvr376/09HT169dP27ZtU1ZWliRp7969ateunccLBAAAsMP2yM2LL76owMBArV69WgsWLFDbtm0lSf/3f/+nwYMHe7xAAAAAO9yaONMkTJzJJHJ2+16IfVMT9uPF8Xtk33imL/vRM31NmDjT9sjNjh07lJ+f73z9l7/8RSNGjNCTTz6pEydO2K8WAADAg2yHmwcffFB79+6VJO3bt0+jRo1So0aNtGrVKj3++OMeLxAAAMAO2+Fm79696tmzpyRp1apVuvrqq/Xaa69p6dKlWrNmjafrAwAAsMV2uLEsS5WVlZJO3wp+5tk20dHROnTokGerAwAAsMl2uElKStLTTz+t5cuXa8OGDRo6dKik0w/3i4yMtF3A/PnzFRsbq5CQECUmJmrTpk1urbdlyxYFBgY6R5EAAACkWoSbOXPmaMeOHRo7dqwmT56sTp06SZJWr16tvn372tpWVlaWxo8fr8mTJ2vnzp0aMGCAUlJSVFhYeM71SktLNWbMGF133XV2ywcAAIbz2K3gP//8swICAtSwYUO31+ndu7cSEhK0YMECZ1tcXJxGjBihzMzMGtcbNWqUOnfurICAAK1bt055eXlufya3gnNbpN2+3Arumb7cpnthvoO3+vIb80zfi3E/eopXbwWvSUhIiK1gc+LECeXm5jqnbzgjOTlZW7durXG9V155RV9//bWmTZvm1ueUl5errKzMZQEAAOayHW4qKir0/PPP68orr1Tr1q3VokULl8Vdhw4dUkVFRZXrdCIjI1VcXFztOl9++aUmTpyoFStWKDDQvZkjMjMzFR4e7lyio6PdrhEAANQ/tsNNRkaGZs2apdtuu02lpaVKT0/Xb37zGzVo0EDTp0+3XYDj7HEsnb4b65dt0ulQdfvttysjI0NdunRxe/uTJk1SaWmpczlw4IDtGgEAQP1he+LMFStW6KWXXtLQoUOVkZGh0aNHq2PHjurRo4c+/vhjjRs3zq3tREREKCAgoMooTUlJSbV3XR09elTbt2/Xzp07NXbsWElSZWWlLMtSYGCg3nvvPV177bVV1gsODlZwcLDdrwkAAOop2yM3xcXFuuyyyyRJTZo0UWlpqSTpxhtv1F//+le3txMUFKTExETl5OS4tOfk5FR711VYWJjy8/OVl5fnXNLS0vSrX/1KeXl56t27t92vAgAADGR75KZdu3YqKirSpZdeqk6dOum9995TQkKCPvnkE9sjJOnp6brzzjuVlJSkPn36aNGiRSosLFRaWpqk06eUDh48qGXLlqlBgwaKj493Wb9Vq1YKCQmp0g4AAC5etsPNzTffrPXr16t379565JFHNHr0aC1evFiFhYWaMGGCrW2lpqbq8OHDmjFjhoqKihQfH6/s7GzFxMRIkoqKis77zBsAAICz1fk5Nx9//LG2bt2qTp06afjw4Z6qy2t4zg3PfLDbl+fceKYvzyC5MN/BW335jXmm78W4Hz3Fzt9v2yM3v3TVVVfpqquuqutmAAAAPMKtcPPmm2+6vcH6MHoDAADM5Va4GTFihFsbczgcqqioqEs9AAAAdeJWuKmsrPR2HQAAAB7hsbmlAAAA/IHb4eaDDz5Qt27dqp14srS0VN27d9fGjRs9WhwAAIBdboebOXPm6P7776/29qvw8HA9+OCDmj17tkeLAwAAsMvtcLNr1y4NHjy4xveTk5OVm5vrkaIAAABqy+1w8/3336thw4Y1vh8YGKgffvjBI0UBAADUltvhpm3btsrPz6/x/U8//VRt2rTxSFEAAAC15Xa4GTJkiKZOnaqff/65yns//fSTpk2bphtvvNGjxQEAANjl9txS33//vRISEhQQEKCxY8fqV7/6lRwOh3bv3q158+apoqJCO3bsUGRkpLdrrhNvzy3l7bk1aot5Vmrfl7mlPNOXeX8uzHfwVl9+Y57pezHuR0/xytxSkZGR2rp1qx566CFNmjRJZzKRw+HQoEGDNH/+fL8PNgAAwHy2Js6MiYlRdna2/vnPf+qrr76SZVnq3Lmzmjdv7q36AAAAbKnVrODNmzfXFVdc4elaAAAA6ozpFwAAgFEINwAAwCiEGwAAYJRaXXMDwLP89RECAFAfMXIDAACMQrgBAABGIdwAAACjEG4AAIBRCDcAAMAohBsAAGAUwg0AADAK4QYAABiFcAMAAIxCuAEAAEYh3AAAAKMQbgAAgFEINwAAwCiEGwAAYBTCDQAAMArhBgAAGIVwAwAAjEK4AQAARiHcAAAAoxBuAACAUQg3AADAKIQbAABgFMKNgRyO0wsAABcjwg0AADAK4QYAABiFcAMAAIxCuAEAAEYh3AAAAKMQbgAAgFEINwAAwCiEGwAAYBTCDQAAMArhBgAAGIVwAwAAjEK4AQAARiHcAAAAoxBuAACAUQg3AADAKIQbAABgFMINAAAwCuEGAAAYxefhZv78+YqNjVVISIgSExO1adOmGvuuXbtWN9xwgy655BKFhYWpT58+evfddy9gtQAAwN/5NNxkZWVp/Pjxmjx5snbu3KkBAwYoJSVFhYWF1fbfuHGjbrjhBmVnZys3N1fXXHONhg0bpp07d17gygEAgL9yWJZl+erDe/furYSEBC1YsMDZFhcXpxEjRigzM9OtbXTv3l2pqamaOnVqte+Xl5ervLzc+bqsrEzR0dEqLS1VWFhY3b5ANRyOf/+3r/bsmRrO/vya6vJ13/Ot7w992Y+e6ct+vDDfwVt9+Y15pu/FuB89paysTOHh4W79/fbZyM2JEyeUm5ur5ORkl/bk5GRt3brVrW1UVlbq6NGjatGiRY19MjMzFR4e7lyio6PrVDcAAPBvPgs3hw4dUkVFhSIjI13aIyMjVVxc7NY2/vSnP+nHH3/UbbfdVmOfSZMmqbS01LkcOHCgTnUDAAD/FujrAhxnj2NJsiyrSlt1Xn/9dU2fPl1/+ctf1KpVqxr7BQcHKzg4uM51AgCA+sFn4SYiIkIBAQFVRmlKSkqqjOb8UlZWlu69916tWrVK119/vTfLBAAA9YzPTksFBQUpMTFROTk5Lu05OTnq27dvjeu9/vrruvvuu/Xaa69p6NCh3i4TAADUMz49LZWenq4777xTSUlJ6tOnjxYtWqTCwkKlpaVJOn29zMGDB7Vs2TJJp4PNmDFj9Oc//1lXXXWVc9QnNDRU4eHhPvseAADAf/g03KSmpurw4cOaMWOGioqKFB8fr+zsbMXExEiSioqKXJ5589///d86deqUHn74YT388MPO9rvuuktLly690OUDAAA/5NPn3PiCnfvka4Pn3NjrezE+84H96L992Te1/w7+0Jf96Jm+Jjznxud3S10M/CHwAABwsfD53FIAAACeRLgBAABGIdwAAACjEG4AAIBRCDcAAMAohBsAAGAUwg0AADAK4QYAABiFcAMAAIxCuAEAAEYh3AAAAKMQbgAAgFEINwAAwCiEGwAAYBTCDQAAMArhBgAAGIVwAwAAjEK4AQAARiHcAAAAoxBuAACAUQg3AADAKIQbAABgFMINAAAwCuEGAAAYhXADAACMQrgBAABGIdwAAACjEG4AAIBRCDcAAMAohBsAAGAUwg0AADAK4QYAABiFcAMAAIxCuAEAAEYJ9HUBFzOH49//bVm+qwMAAJMwcgMAAIxCuAEAAEYh3AAAAKMQbgAAgFEINwAAwCjcLeVnuIMKAIC6YeQGAAAYhXADAACMQrgBAABGIdwAAACjEG4AAIBRuFuqnqjuLirurAIAoCpGbgAAgFEINwAAwCiEGwAAYBTCDQAAMArhBgAAGIVwAwAAjEK4AQAARiHcAAAAoxBuAACAUQg3AADAKIQbAABgFJ+Hm/nz5ys2NlYhISFKTEzUpk2bztl/w4YNSkxMVEhIiDp06KCFCxdeoEoBAEB94NNwk5WVpfHjx2vy5MnauXOnBgwYoJSUFBUWFlbbv6CgQEOGDNGAAQO0c+dOPfnkkxo3bpzWrFlzgSsHAAD+ymFZvptPunfv3kpISNCCBQucbXFxcRoxYoQyMzOr9H/iiSf05ptvavfu3c62tLQ07dq1Sx999JFbn1lWVqbw8HCVlpYqLCys7l/iF+zM3u3tvudb3x/6+mrf2OnLfvRMX/bjhfkO3urLb8wzfS/G/egpdv5+B3r+491z4sQJ5ebmauLEiS7tycnJ2rp1a7XrfPTRR0pOTnZpGzRokBYvXqyTJ0+qYcOGVdYpLy9XeXm583Vpaamk0zvJ26r7iJo+1ht9L+RnmdzXX+uqb339tS5/6OuvddW3vv5aV33r663Pqqszf7fdGpOxfOTgwYOWJGvLli0u7TNnzrS6dOlS7TqdO3e2Zs6c6dK2ZcsWS5L13XffVbvOtGnTLEksLCwsLCwsBiwHDhw4b8bw2cjNGY6zx7EkWZZVpe18/atrP2PSpElKT093vq6srNSRI0fUsmXLc36OO8rKyhQdHa0DBw545RQXPI9jVv9wzOonjlv94+/HzLIsHT16VFFRUeft67NwExERoYCAABUXF7u0l5SUKDIystp1WrduXW3/wMBAtWzZstp1goODFRwc7NLWrFmz2hdejbCwML/8IaBmHLP6h2NWP3Hc6h9/Pmbh4eFu9fPZ3VJBQUFKTExUTk6OS3tOTo769u1b7Tp9+vSp0v+9995TUlJStdfbAACAi49PbwVPT0/Xyy+/rCVLlmj37t2aMGGCCgsLlZaWJun0KaUxY8Y4+6elpWn//v1KT0/X7t27tWTJEi1evFiPPvqor74CAADwMz695iY1NVWHDx/WjBkzVFRUpPj4eGVnZysmJkaSVFRU5PLMm9jYWGVnZ2vChAmaN2+eoqKiNHfuXI0cOdIn9QcHB2vatGlVTnvBf3HM6h+OWf3Ecat/TDpmPn3ODQAAgKf5fPoFAAAATyLcAAAAoxBuAACAUQg3AADAKISbWpo/f75iY2MVEhKixMREbdq0ydcl4f/LzMzUFVdcoaZNm6pVq1YaMWKE9uzZ49LHsixNnz5dUVFRCg0N1a9//Wt9/vnnPqoYv5SZmSmHw6Hx48c72zhm/ungwYO644471LJlSzVq1Eg9e/ZUbm6u832Om385deqU/vM//1OxsbEKDQ1Vhw4dNGPGDFVWVjr7GHHMzjtBA6pYuXKl1bBhQ+ull16yvvjiC+uRRx6xGjdubO3fv9/XpcGyrEGDBlmvvPKK9dlnn1l5eXnW0KFDrUsvvdQ6duyYs8+zzz5rNW3a1FqzZo2Vn59vpaamWm3atLHKysp8WDksy7K2bdtmtW/f3urRo4f1yCOPONs5Zv7nyJEjVkxMjHX33Xdbf//7362CggLr/ffft7766itnH46bf3n66aetli1bWm+//bZVUFBgrVq1ymrSpIk1Z84cZx8TjhnhphauvPJKKy0tzaWta9eu1sSJE31UEc6lpKTEkmRt2LDBsizLqqystFq3bm09++yzzj4///yzFR4ebi1cuNBXZcKyrKNHj1qdO3e2cnJyrIEDBzrDDcfMPz3xxBNW//79a3yf4+Z/hg4dav3ud79zafvNb35j3XHHHZZlmXPMOC1l04kTJ5Sbm6vk5GSX9uTkZG3dutVHVeFcSktLJUktWrSQJBUUFKi4uNjlGAYHB2vgwIEcQx97+OGHNXToUF1//fUu7Rwz//Tmm28qKSlJt956q1q1aqVevXrppZdecr7PcfM//fv31/r167V3715J0q5du7R582YNGTJEkjnHzOezgtc3hw4dUkVFRZXJPSMjI6tM6gnfsyxL6enp6t+/v+Lj4yXJeZyqO4b79++/4DXitJUrV2rHjh365JNPqrzHMfNP+/bt04IFC5Senq4nn3xS27Zt07hx4xQcHKwxY8Zw3PzQE088odLSUnXt2lUBAQGqqKjQzJkzNXr0aEnm/L9GuKklh8Ph8tqyrCpt8L2xY8fq008/1ebNm6u8xzH0HwcOHNAjjzyi9957TyEhITX245j5l8rKSiUlJemZZ56RJPXq1Uuff/65FixY4DIvIMfNf2RlZenVV1/Va6+9pu7duysvL0/jx49XVFSU7rrrLme/+n7MOC1lU0REhAICAqqM0pSUlFRJuvCtP/zhD3rzzTf14Ycfql27ds721q1bSxLH0I/k5uaqpKREiYmJCgwMVGBgoDZs2KC5c+cqMDDQeVw4Zv6lTZs26tatm0tbXFycc05A/l/zP4899pgmTpyoUaNG6bLLLtOdd96pCRMmKDMzU5I5x4xwY1NQUJASExOVk5Pj0p6Tk6O+ffv6qCqczbIsjR07VmvXrtUHH3yg2NhYl/djY2PVunVrl2N44sQJbdiwgWPoI9ddd53y8/OVl5fnXJKSkvTb3/5WeXl56tChA8fMD/Xr16/KYxb27t3rnPyY/9f8z/Hjx9Wggeuf/oCAAOet4MYcMx9ezFxvnbkVfPHixdYXX3xhjR8/3mrcuLH1zTff+Lo0WJb10EMPWeHh4dbf/vY3q6ioyLkcP37c2efZZ5+1wsPDrbVr11r5+fnW6NGj692tjqY7+24py+KY+aNt27ZZgYGB1syZM60vv/zSWrFihdWoUSPr1VdfdfbhuPmXu+66y2rbtq3zVvC1a9daERER1uOPP+7sY8IxI9zU0rx586yYmBgrKCjISkhIcN5mDN+TVO3yyiuvOPtUVlZa06ZNs1q3bm0FBwdbV199tZWfn++7olHFL8MNx8w/vfXWW1Z8fLwVHBxsde3a1Vq0aJHL+xw3/1JWVmY98sgj1qWXXmqFhIRYHTp0sCZPnmyVl5c7+5hwzByWZVm+HDkCAADwJK65AQAARiHcAAAAoxBuAACAUQg3AADAKIQbAABgFMINAAAwCuEGAAAYhXADAACMQrgBYASHw6F169Zd8M9dunSpmjVrdsE/F0DNCDcA6szhcJxzufvuu2u97fbt22vOnDkeq/Vcpk+frp49e16QzwLgPYG+LgBA/VdUVOT876ysLE2dOtVltujQ0FBflAXgIsXIDYA6a926tXMJDw+Xw+Fwadu4caMSExMVEhKiDh06KCMjQ6dOnXKuP336dF166aUKDg5WVFSUxo0bJ0n69a9/rf3792vChAnOUaBzKSoqUkpKikJDQxUbG6tVq1a5vP/EE0+oS5cuatSokTp06KApU6bo5MmTkk6fXsrIyNCuXbucn7V06VJJ0r/+9S898MADioyMVEhIiOLj4/X222+7bPvdd99VXFycmjRposGDB7sEPgAXFiM3ALzq3Xff1R133KG5c+dqwIAB+vrrr/XAAw9IkqZNm6bVq1dr9uzZWrlypbp3767i4mLt2rVLkrR27VpdfvnleuCBB3T//fef97OmTJmiZ599Vn/+85+1fPlyjR49WvHx8YqLi5MkNW3aVEuXLlVUVJTy8/N1//33q2nTpnr88ceVmpqqzz77TO+8847ef/99SVJ4eLgqKyuVkpKio0eP6tVXX1XHjh31xRdfKCAgwPm5x48f1/PPP6/ly5erQYMGuuOOO/Too49qxYoVnt6dANzh62nJAZjllVdescLDw52vBwwYYD3zzDMufZYvX261adPGsizL+tOf/mR16dLFOnHiRLXbi4mJsWbPnn3ez5VkpaWlubT17t3beuihh2pc57nnnrMSExOdr6dNm2ZdfvnlLn3effddq0GDBtaePXuq3cYrr7xiSbK++uorZ9u8efOsyMjI89YMwDsYuQHgVbm5ufrkk080c+ZMZ1tFRYV+/vlnHT9+XLfeeqvmzJmjDh06aPDgwRoyZIiGDRumwED7/zz16dOnyuu8vDzn69WrV2vOnDn66quvdOzYMZ06dUphYWHn3GZeXp7atWunLl261NinUaNG6tixo/N1mzZtVFJSYrt+AJ7BNTcAvKqyslIZGRnKy8tzLvn5+fryyy8VEhKi6Oho7dmzR/PmzVNoaKh+//vf6+qrr3ZeC1NXZ67T+fjjjzVq1CilpKTo7bff1s6dOzV58mSdOHHinOu7czF0w4YNq3ymZVm1LxpAnTByA8CrEhIStGfPHnXq1KnGPqGhoRo+fLiGDx+uhx9+WF27dlV+fr4SEhIUFBSkiooKtz7r448/1pgxY1xe9+rVS5K0ZcsWxcTEaPLkyc739+/f77J+dZ/Vo0cPffvtt9q7d+85R28A+A/CDQCvmjp1qm688UZFR0fr1ltvVYMGDfTpp58qPz9fTz/9tJYuXaqKigr17t1bjRo10vLlyxUaGqqYmBhJp59zs3HjRo0aNUrBwcGKiIio8bNWrVqlpKQk9e/fXytWrNC2bdu0ePFiSVKnTp1UWFiolStX6oorrtBf//pXvfHGGy7rt2/fXgUFBc5TUU2bNtXAgQN19dVXa+TIkZo1a5Y6deqkf/zjH3I4HBo8eLD3dhyAWuO0FACvGjRokN5++23l5OToiiuu0FVXXaVZs2Y5w0uzZs300ksvqV+/furRo4fWr1+vt956Sy1btpQkzZgxQ9988406duyoSy655JyflZGRoZUrV6pHjx76n//5H61YsULdunWTJN10002aMGGCxo4dq549e2rr1q2aMmWKy/ojR47U4MGDdc011+iSSy7R66+/Lklas2aNrrjiCo0ePVrdunXT448/7vZoEoALz2FxYhgAABiEkRsAAGAUwg0AADAK4QYAABiFcAMAAIxCuAEAAEYh3AAAAKMQbgAAgFEINwAAwCiEGwAAYBTCDQAAMArhBgAAGOX/AYFH3/mWxs8oAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier_detector_all took 14.454051971435547 seconds\n",
      "\n",
      " real_world_data/electricity_dataset.csv encoder: None scaler: minmax PCA preprocess: True\n",
      "Classifier: [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83] (0.8148148148148148, 0.9107142857142857)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def run_rw_detectors(X_train, X_test_batches, y_train, filename, real_drifts, encoder=None, scaler=None, pca_preprocess=False):\n",
    "    ref_data = X_train\n",
    "    test_batches = X_test_batches\n",
    "    ref_labels = y_train\n",
    "    \n",
    "#     timer = time()\n",
    "#     drifts_pca_ref = syncstream_pca_all(ref_data, test_batches, ref_labels, encoder, scaler)\n",
    "#     print(\"syncstream_pca_all took\", time() - timer, \"seconds\")\n",
    "    \n",
    "#     timer = time()\n",
    "#     drifts_stat_ref = syncstream_stat_all(ref_data, test_batches, ref_labels, encoder, scaler)\n",
    "#     print(\"syncstream_stat_all took\", time() - timer, \"seconds\")\n",
    "    \n",
    "#     drifts_scd_unidir = []\n",
    "#     if encoder != \"onehot\": # due to matrix errors\n",
    "#         timer = time()\n",
    "#         drifts_scd_unidir = scd_all(ref_data, test_batches, ref_labels, encoder, scaler)\n",
    "#         print(\"scd_all took\", time() - timer, \"seconds\")\n",
    "\n",
    "#     drifts_scd_bidir = []\n",
    "#     if encoder != \"onehot\": # due to matrix errors\n",
    "#         timer = time()\n",
    "#         drifts_scd_bidir = scd_all(ref_data, test_batches, ref_labels, encoder, scaler, bidirectional=True)\n",
    "#         print(\"scd_all (bidir) took\", time() - timer, \"seconds\")\n",
    "\n",
    "    timer = time()\n",
    "    drifts_classifier = classifier_detector_all(ref_data, test_batches, ref_labels, encoder, scaler, pca_preprocess)\n",
    "    print(\"classifier_detector_all took\", time() - timer, \"seconds\")\n",
    "\n",
    "    print(\"\\n\", filename, \"encoder:\", encoder, \"scaler:\", scaler, \"PCA preprocess:\", pca_preprocess)\n",
    "    report_1 = [\n",
    "#         \"PCA_ref:\",\n",
    "#         drifts_pca_ref,\n",
    "#         postprocess_rw(real_drifts, drifts_pca_ref, len(test_batches)),\n",
    "#         \"Stat_ref:\",\n",
    "#         drifts_stat_ref,\n",
    "#         postprocess_rw(real_drifts, drifts_stat_ref, len(test_batches)),\n",
    "#         \"SCD_unidir:\",\n",
    "#         drifts_scd_unidir,\n",
    "#         postprocess_rw(real_drifts, drifts_scd_unidir, len(test_batches)),\n",
    "        \"Classifier:\",\n",
    "        drifts_classifier,\n",
    "        postprocess_rw(real_drifts, drifts_classifier, len(test_batches))\n",
    "    ]\n",
    "    report_2 = [\n",
    "#         \"SCD_bidir:\",\n",
    "#         drifts_scd_bidir,\n",
    "#         postprocess_rw(real_drifts, drifts_scd_bidir, len(test_batches))\n",
    "    ]\n",
    "\n",
    "    print(*report_1)\n",
    "    print(*report_2, \"\\n\")\n",
    "    \n",
    "\n",
    "def run_airlines():\n",
    "    filename = \"real_world_data/airline_dataset.csv\"\n",
    "\n",
    "    data = pd.read_csv(filename)\n",
    "    df = pd.DataFrame(data)\n",
    "    train = df.iloc[:179794,:]\n",
    "    test = df.iloc[179794:,:]\n",
    "    \n",
    "    X_train = train.drop(columns=[\"Delay\", \"Unnamed: 0\"])\n",
    "    X_test = test.drop(columns=[\"Delay\", \"Unnamed: 0\"])\n",
    "    y_train = train[[\"Delay\"]]\n",
    "    y_test = test[[\"Delay\"]]\n",
    "    \n",
    "    X_test_batches = []\n",
    "\n",
    "    i = 0\n",
    "    while i < len(X_test):\n",
    "        new_i = i + 17000\n",
    "        if new_i > len(X_test):\n",
    "            new_i = len(X_test)\n",
    "        X_test_batches.append(X_test[i: new_i])\n",
    "        i = new_i\n",
    "        \n",
    "    # See drift definitions\n",
    "    real_drifts = [2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22]\n",
    "\n",
    "#     run_rw_detectors(X_train, X_test_batches, y_train, filename, real_drifts, encoder=\"onehot\", scaler=None)\n",
    "#     run_rw_detectors(X_train, X_test_batches, y_train, filename, real_drifts, encoder=\"onehot\", scaler=\"minmax\")\n",
    "#     run_rw_detectors(X_train, X_test_batches, y_train, filename, real_drifts, encoder=\"ordinal\", scaler=None)\n",
    "#     run_rw_detectors(X_train, X_test_batches, y_train, filename, real_drifts, encoder=\"ordinal\", scaler=\"minmax\")\n",
    "    run_rw_detectors(X_train, X_test_batches, y_train, filename, real_drifts, encoder=\"target\", scaler=None)\n",
    "    run_rw_detectors(X_train, X_test_batches, y_train, filename, real_drifts, encoder=\"target\", scaler=\"minmax\")\n",
    "    run_rw_detectors(X_train, X_test_batches, y_train, filename, real_drifts, encoder=\"target\", scaler=None, pca_preprocess=True)\n",
    "    run_rw_detectors(X_train, X_test_batches, y_train, filename, real_drifts, encoder=\"target\", scaler=\"minmax\", pca_preprocess=True)\n",
    "\n",
    "    \n",
    "def run_elect2():\n",
    "    filename = \"real_world_data/electricity_dataset.csv\"\n",
    "    \n",
    "    data = pd.read_csv(filename)\n",
    "    df = pd.DataFrame(data).drop(columns=[\"Unnamed: 0\", \"real_date\"])\n",
    "    \n",
    "    df[\"day\"] = df[\"day\"].apply(lambda x: float(x.split(\"\\'\")[1]))\n",
    "    \n",
    "#     print(df)\n",
    "#     print(np.linalg.matrix_rank(df))\n",
    "    \n",
    "    train = df.iloc[:15104,:]\n",
    "    test = df.iloc[15104:,:]\n",
    "    \n",
    "    X_train = train.drop(columns=[\"label\"])\n",
    "    X_test = test.drop(columns=[\"label\"])\n",
    "\n",
    "    y_train = train[[\"label\"]]\n",
    "    y_test = test[[\"label\"]]\n",
    "\n",
    "    # Preprocess with PCA to avoid linear algebra errors in SCD\n",
    "#     pca = PCA()\n",
    "#     X_train = pd.DataFrame(pca.fit_transform(X_train))\n",
    "#     X_test = pd.DataFrame(pca.transform(X_test))\n",
    "    \n",
    "#     print(X_train)\n",
    "#     print(np.linalg.matrix_rank(X_train))\n",
    "    \n",
    "    X_test_batches = []\n",
    "\n",
    "    i = 0\n",
    "    while i < len(X_test):\n",
    "        new_i = i + 365\n",
    "        if new_i > len(X_test):\n",
    "            new_i = len(X_test)\n",
    "        X_test_batches.append(X_test[i: new_i])\n",
    "        i = new_i\n",
    "    \n",
    "    real_drifts = [2,4,11,12,13,14,15,16,18,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,59,60,62,63,65,66,67,76,80,81,83]\n",
    "    \n",
    "#     run_rw_detectors(X_train, X_test_batches, y_train, filename, real_drifts, encoder=None, scaler=None)\n",
    "    run_rw_detectors(X_train, X_test_batches, y_train, filename, real_drifts, encoder=None, scaler=\"minmax\")\n",
    "#     run_rw_detectors(X_train, X_test_batches, y_train, filename, real_drifts, encoder=None, scaler=None, pca_preprocess=True)\n",
    "    run_rw_detectors(X_train, X_test_batches, y_train, filename, real_drifts, encoder=None, scaler=\"minmax\", pca_preprocess=True)\n",
    "    \n",
    "    \n",
    "def run_weather(monthly):\n",
    "    filename = \"real_world_data/weather_dataset.csv\"\n",
    "    \n",
    "    data = pd.read_csv(filename)\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    train = df.iloc[:6053,:]\n",
    "    test = df.iloc[6053:,:]\n",
    "    \n",
    "    X_train = train.drop(columns=[\"Label_Rain\", \"Unnamed: 0\"])\n",
    "    X_test = test.drop(columns=[\"Label_Rain\", \"Unnamed: 0\"])\n",
    "    \n",
    "    y_train = train[[\"Label_Rain\"]]\n",
    "    y_test = test[[\"Label_Rain\"]]\n",
    "    \n",
    "    batch_size = 365\n",
    "    label = filename + \" yearly\"\n",
    "    real_drifts = [ 2, 3, 4, 6, 11, 12, 15, 16, 17, 18, 22, 24, 25, 27, 28, 29, 32, 33 ]\n",
    "    if monthly:\n",
    "        batch_size = 30\n",
    "        label = filename + \" monthly\"\n",
    "        real_drifts = [11,12,14,18,28,31,35,43,47,48,49,69,92,96,103,108,125,143,145,147,154,162,167,173,174,175,176,177,178,183,185,186,192,197,205,209,210,214,215,217,220,228,246,247,260,265,266,281,283,284,297,302,319,322,323,324,327,335,338,350,353,357,362,383,384,387,389,397,399,400]\n",
    "        \n",
    "    # Preprocess with PCA to avoid linear algebra errors in SCD\n",
    "    pca = PCA()\n",
    "    X_train = pd.DataFrame(pca.fit_transform(X_train))\n",
    "    X_test = pd.DataFrame(pca.transform(X_test))\n",
    "    \n",
    "    X_test_batches = []\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(X_test):\n",
    "        new_i = i + batch_size\n",
    "        if new_i > len(X_test):\n",
    "            new_i = len(X_test)\n",
    "        X_test_batches.append(X_test[i: new_i])\n",
    "        i = new_i\n",
    "        \n",
    "    run_rw_detectors(X_train, X_test_batches, y_train, label, real_drifts, encoder=None, scaler=None)\n",
    "    run_rw_detectors(X_train, X_test_batches, y_train, label, real_drifts, encoder=None, scaler=\"minmax\")\n",
    "    \n",
    "    \n",
    "def run_spam(batch_size):\n",
    "    filename = \"real_world_data/spam_dataset.csv\"\n",
    "    \n",
    "    data = pd.read_csv(filename)\n",
    "    df = pd.DataFrame(data).drop(columns=[\"Unnamed: 0\"])\n",
    "    \n",
    "    train = df.iloc[:1468,:]\n",
    "    test = df.iloc[1468:,:]\n",
    "    \n",
    "    X_train = train.drop(columns=[\"ACTUAL_LABEL\"])\n",
    "    X_test = test.drop(columns=[\"ACTUAL_LABEL\"])\n",
    "    \n",
    "    print(X_train)\n",
    "    print(np.linalg.matrix_rank(X_train))\n",
    "    \n",
    "    y_train = train[[\"ACTUAL_LABEL\"]]\n",
    "    y_test = test[[\"ACTUAL_LABEL\"]]\n",
    "    \n",
    "    # Preprocess with PCA to avoid linear algebra errors in SCD\n",
    "    pca = PCA(n_components=100)\n",
    "    X_train = pd.DataFrame(pca.fit_transform(X_train))\n",
    "    X_test = pd.DataFrame(pca.transform(X_test))\n",
    "    \n",
    "    X_test_batches = []\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(X_test):\n",
    "        new_i = i + batch_size\n",
    "        if new_i > len(X_test):\n",
    "            new_i = len(X_test)\n",
    "        X_test_batches.append(X_test[i: new_i])\n",
    "        i = new_i\n",
    "        \n",
    "    print(\"batches:\", len(X_test_batches))\n",
    "    \n",
    "    real_drifts = [3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
    "    if batch_size == 50:\n",
    "        real_drifts = [1, 3, 4, 5, 7, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58]\n",
    "    elif batch_size == 20:\n",
    "        real_drifts = [2, 10, 11, 14, 17, 21, 22, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 41, 42, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 70, 72, 73, 74, 76, 77, 78, 79, 80, 82, 83, 85, 86, 87, 88, 90, 92, 93, 95, 97, 98, 99, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145]\n",
    "    \n",
    "    label = filename + \" \" + str(batch_size)\n",
    "        \n",
    "    run_rw_detectors(X_train, X_test_batches, y_train, label, real_drifts, encoder=None, scaler=None)\n",
    "    run_rw_detectors(X_train, X_test_batches, y_train, label, real_drifts, encoder=None, scaler=\"minmax\")\n",
    "    \n",
    "# run_airlines()\n",
    "run_elect2()\n",
    "# run_weather(monthly=True)\n",
    "# run_weather(monthly=False)\n",
    "# for i in range(10):\n",
    "#     run_spam(batch_size=100)\n",
    "#     run_spam(batch_size=50)\n",
    "#     run_spam(batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae96b7b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For developing the stat/crit graphs\n",
    "\n",
    "# deltas = [-500, -112.33805834087934, -5.63757670366158, -254.64638163367908, -105.95361974932212, -277.2522005160049, -0.7797701869503726, -17.160444052856292, 0.6515078028928656, -500, 81.65627519798909, -251.6647424837547, -104.890988106441, -500, -362.3305095837991, -155.8376577058052, -153.27112026764098, 104.28955944645986, 103.35571477773283, -198.54996551748536, -9.33669177511274, -139.4456957732, -500, -500, -164.03845542809495, -203.69279570797062, -309.29205775200353, 30.91586674598011, -221.1829434006777, -71.75523475546379, -0.4561412892317094, 180.17201171699162, -180.71892697522435, -92.823026451837]\n",
    "# crits = [-112.87767355681257, -112.87767355681257, -112.87767355681257, -112.87767355681257, -112.87767355681257, -112.87767355681257, -112.87767355681257, -112.87767355681257, -112.87767355681257, -112.87767355681257, -112.87767355681257, -112.87767355681257, -112.87767355681257, -112.87767355681257, -112.87767355681257, -112.87767355681257, -112.87767355681257, -112.87767355681257, -112.87767355681257, -112.87767355681257, -112.87767355681257, -112.87767355681257, -112.87767355681257, -112.87767355681257, -112.87767355681257, -112.87767355681257, -112.87767355681257, -112.87767355681257, -112.87767355681257, -112.87767355681257, -112.87767355681257, -112.87767355681257, -112.87767355681257, -44.02884159020756]\n",
    "# y_label = \"SCD (unidirectional)\"\n",
    "# deltas_reverse = [-626.5247613554766, 462.732832569769, 1228.4724605070069, 1428.1028153758189, 1252.3197326216869, -2360.207044655568, -2482.9791209586383]\n",
    "# crits_reverse = [-1722.3482489631685, -1709.2903407223453, -1790.3885036189583, -1784.6916262708824, -1774.6846479583753, -1828.9015713027097, -1820.821524179729]\n",
    "\n",
    "# graph(deltas, crits, y_label)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
